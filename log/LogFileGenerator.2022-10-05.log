17:32:17.306 [sbt-bg-threads-1] ERROR HelperUtils.ObtainConfigReference$ - Failed to retrieve config entry randomLogGenerator for reason com.typesafe.config.ConfigException$Missing: merge of system properties,application.conf @ jar:file:/C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_d2d13988/job-1/target/456637b1/fb61813d/homework1_3-0.1.0-SNAPSHOT.jar!/application.conf: 1: No configuration setting found for key 'randomLogGenerator'
17:34:14.333 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Input path recieved by MapReduce Task 1:1
17:34:14.336 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Output path recieved by MapReduce Task 1:\input\data.txt
17:34:14.564 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:34:14.565 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:34:14.573 [sbt-bg-threads-1] WARN  org.apache.hadoop.util.Shell - Did not find winutils.exe: {}
java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\Hadoop\hadoop-3.3.4\bin\bin -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.getQualifiedBinInner(Shell.java:607)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3741)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3736)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3520)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288)
	at org.apache.hadoop.mapred.JobConf.getWorkingDirectory(JobConf.java:672)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:470)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:52)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:34:14.581 [sbt-bg-threads-1] DEBUG org.apache.hadoop.util.Shell - Failed to find winutils.exe
java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\Hadoop\hadoop-3.3.4\bin\bin -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.getQualifiedBinInner(Shell.java:607)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3741)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3736)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3520)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288)
	at org.apache.hadoop.mapred.JobConf.getWorkingDirectory(JobConf.java:672)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:470)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:52)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:34:14.686 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"GetGroups"})
17:34:14.711 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"})
17:34:14.713 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"})
17:34:14.715 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since last successful login"})
17:34:14.717 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since startup"})
17:34:14.727 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
17:34:14.760 [sbt-bg-threads-1] DEBUG o.a.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
17:34:14.791 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
17:34:14.794 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
17:34:15.286 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
17:34:15.288 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
17:34:15.288 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
17:34:15.308 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
17:34:15.369 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Hadoop login
17:34:15.370 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - hadoop login commit
17:34:15.373 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using local user: NTUserPrincipal: harsh
17:34:15.374 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using user: "NTUserPrincipal: harsh" with name: harsh
17:34:15.375 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - User entry: "harsh"
17:34:15.377 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - UGI loginUser: harsh (auth:SIMPLE)
17:34:15.379 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Acquiring creator semaphore for file:///
17:34:15.380 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Acquiring creator semaphore for file:///: duration 0:00.001s
17:34:15.383 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Creating FS file:///
17:34:15.383 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
17:34:15.401 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_fd6c5c93/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:34:15.413 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_fd6c5c93/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:34:15.416 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_fd6c5c93/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:34:15.419 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_fd6c5c93/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:34:15.421 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_fd6c5c93/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:34:15.433 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_fd6c5c93/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:34:15.445 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_fd6c5c93/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:34:15.447 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_fd6c5c93/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:34:15.447 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
17:34:15.449 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
17:34:15.459 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
17:34:15.460 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
17:34:15.465 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Creating FS file:///: duration 0:00.083s
17:34:15.486 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:34:15.486 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:34:15.487 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:34:15.492 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:34:15.494 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from system property: null
17:34:15.495 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from environment variable: null
17:34:15.599 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2-jobtracker.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@793431c[fileName=hadoop-metrics2-jobtracker.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:34:15.603 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@2c09441f[fileName=hadoop-metrics2.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:34:15.667 [sbt-bg-threads-1] WARN  o.a.h.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
17:34:15.672 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: period
17:34:15.673 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: periodMillis
17:34:15.683 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.metrics2.impl.MetricsSystemImpl.droppedPubAll with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Dropped updates by all sinks"})
17:34:15.685 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Publish", "Publishing stats"})
17:34:15.687 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Snapshot", "Snapshot stats"})
17:34:15.694 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:34:15.695 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:34:15.695 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:34:15.837 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:34:15.839 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:34:15.840 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:34:15.841 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sources, name=NumActiveSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sources, name=NumAllSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sinks, name=NumActiveSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sinks, name=NumAllSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Dropped updates by all sinks, name=DroppedPubAll, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for publishing stats, name=PublishNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for publishing stats, name=PublishAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for snapshot stats, name=SnapshotNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for snapshot stats, name=SnapshotAvgTime, type=java.lang.Double, read-only, descriptor={}]]
17:34:15.906 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:34:15.912 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Stats
17:34:15.913 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source MetricsSystem,sub=Stats registered.
17:34:15.917 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
17:34:15.918 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system started
17:34:15.924 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:34:15.925 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:34:15.926 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:34:15.929 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:34:15.930 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:34:15.930 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:34:15.931 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for getGroups, name=GetGroupsNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for getGroups, name=GetGroupsAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since last successful login, name=RenewalFailures, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since startup, name=RenewalFailuresTotal, type=java.lang.Long, read-only, descriptor={}]]
17:34:15.934 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:34:15.937 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=UgiMetrics
17:34:15.942 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source UgiMetrics registered.
17:34:15.944 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source UgiMetrics
17:34:15.949 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Control
17:34:15.954 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:34:15.956 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:34:15.957 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:34:15.958 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:34:15.964 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-1011775406, LocalJobRunnerMetrics
17:34:15.965 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:34:15.969 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:34:15.970 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:34:15.973 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:34:15.974 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:34:15.975 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:34:15.976 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:34:15.977 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:34:15.978 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-1011775406
17:34:15.978 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-1011775406 registered.
17:34:15.979 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-1011775406
17:34:15.980 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:34:15.987 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapred.JobClient$1@1e02d407]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:34:16.006 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$10@7b8362ec]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.connect(Job.java:1536)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1565)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:34:16.009 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:34:16.010 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:34:16.014 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:34:16.015 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:34:16.017 [sbt-bg-threads-1] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
17:34:16.018 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:34:16.019 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:34:16.172 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:34:16.173 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:34:16.174 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics--742188355, LocalJobRunnerMetrics
17:34:16.175 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:34:16.176 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:34:16.176 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:34:16.177 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:34:16.177 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:34:16.178 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:34:16.178 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:34:16.179 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:34:16.179 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics--742188355
17:34:16.180 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics--742188355 registered.
17:34:16.180 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics--742188355
17:34:16.181 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:34:16.182 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Cluster$1@104dfed]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:193)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:34:16.197 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:34:16.206 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$11@46d0ede2]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:34:16.210 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:34:16.222 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:34:16.242 [sbt-bg-threads-1] DEBUG o.a.hadoop.mapreduce.JobSubmitter - Configuring job job_local1341066260_0001 with file:/tmp/hadoop/mapred/staging/harsh1341066260/.staging/job_local1341066260_0001 as the submit dir
17:34:16.243 [sbt-bg-threads-1] DEBUG o.a.hadoop.mapreduce.JobSubmitter - adding the following namenodes' delegation tokens:[local]
17:34:16.300 [sbt-bg-threads-1] WARN  o.a.h.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
17:34:16.300 [sbt-bg-threads-1] DEBUG o.a.h.mapreduce.JobResourceUploader - default FileSystem: file:///
17:34:16.317 [sbt-bg-threads-1] DEBUG o.apache.hadoop.io.nativeio.NativeIO - Initialized cache for IDs to User/Group mapping with a  cache timeout of 14400 seconds.
17:34:16.319 [sbt-bg-threads-1] INFO  o.a.hadoop.mapreduce.JobSubmitter - Cleaning up the staging area file:/tmp/hadoop/mapred/staging/harsh1341066260/.staging/job_local1341066260_0001
17:34:16.320 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.io.nativeio.NativeIOException: No such file or directory
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.chmod(NativeIO.java:388)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:974)
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:591)
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:572)
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:594)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:752)
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:660)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:34:16.324 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.io.nativeio.NativeIOException: No such file or directory
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.chmod(NativeIO.java:388)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:974)
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:591)
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:572)
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:594)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:752)
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:660)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:34:16.667 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (harsh (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 4a8f02b9
17:34:16.668 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 4448f598
17:34:16.672 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - Completed shutdown in 0.006 seconds; Timeouts: 0
17:34:16.684 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - ShutdownHookManager completed shutdown.
17:35:05.357 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Input path recieved by MapReduce Task 1:1
17:35:05.361 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Output path recieved by MapReduce Task 1:\input\data.txt
17:35:05.604 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:35:05.605 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:35:05.615 [sbt-bg-threads-1] WARN  org.apache.hadoop.util.Shell - Did not find winutils.exe: {}
java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\Hadoop\hadoop-3.3.4\bin\bin -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.getQualifiedBinInner(Shell.java:607)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3741)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3736)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3520)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288)
	at org.apache.hadoop.mapred.JobConf.getWorkingDirectory(JobConf.java:672)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:470)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:52)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:35:05.624 [sbt-bg-threads-1] DEBUG org.apache.hadoop.util.Shell - Failed to find winutils.exe
java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\Hadoop\hadoop-3.3.4\bin\bin -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.getQualifiedBinInner(Shell.java:607)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3741)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3736)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3520)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288)
	at org.apache.hadoop.mapred.JobConf.getWorkingDirectory(JobConf.java:672)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:470)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:52)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:35:05.694 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"GetGroups"})
17:35:05.698 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"})
17:35:05.700 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"})
17:35:05.702 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since last successful login"})
17:35:05.704 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since startup"})
17:35:05.713 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
17:35:05.746 [sbt-bg-threads-1] DEBUG o.a.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
17:35:05.772 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
17:35:05.775 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
17:35:05.790 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
17:35:05.793 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
17:35:05.794 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
17:35:05.827 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
17:35:05.879 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Hadoop login
17:35:05.881 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - hadoop login commit
17:35:05.884 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using local user: NTUserPrincipal: harsh
17:35:05.884 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using user: "NTUserPrincipal: harsh" with name: harsh
17:35:05.885 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - User entry: "harsh"
17:35:05.887 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - UGI loginUser: harsh (auth:SIMPLE)
17:35:05.890 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Acquiring creator semaphore for file:///
17:35:05.891 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Acquiring creator semaphore for file:///: duration 0:00.001s
17:35:05.894 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Creating FS file:///
17:35:05.895 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
17:35:05.915 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_e782f953/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:35:05.923 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_e782f953/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:35:05.926 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_e782f953/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:35:05.928 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_e782f953/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:35:05.930 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_e782f953/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:35:05.943 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_e782f953/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:35:05.953 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_e782f953/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:35:05.955 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_e782f953/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:35:05.956 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
17:35:05.957 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
17:35:05.973 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
17:35:05.974 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
17:35:05.981 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Creating FS file:///: duration 0:00.087s
17:35:06.006 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:35:06.007 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:35:06.008 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:35:06.015 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:35:06.018 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from system property: null
17:35:06.018 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from environment variable: null
17:35:06.081 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2-jobtracker.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@2ba6d473[fileName=hadoop-metrics2-jobtracker.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:35:06.085 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@5359d930[fileName=hadoop-metrics2.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:35:06.090 [sbt-bg-threads-1] WARN  o.a.h.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
17:35:06.093 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: period
17:35:06.094 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: periodMillis
17:35:06.101 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.metrics2.impl.MetricsSystemImpl.droppedPubAll with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Dropped updates by all sinks"})
17:35:06.102 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Publish", "Publishing stats"})
17:35:06.106 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Snapshot", "Snapshot stats"})
17:35:06.112 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:35:06.112 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:35:06.113 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:35:06.190 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:35:06.191 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:35:06.192 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:35:06.193 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sources, name=NumActiveSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sources, name=NumAllSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sinks, name=NumActiveSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sinks, name=NumAllSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Dropped updates by all sinks, name=DroppedPubAll, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for publishing stats, name=PublishNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for publishing stats, name=PublishAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for snapshot stats, name=SnapshotNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for snapshot stats, name=SnapshotAvgTime, type=java.lang.Double, read-only, descriptor={}]]
17:35:06.214 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:35:06.215 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Stats
17:35:06.216 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source MetricsSystem,sub=Stats registered.
17:35:06.218 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
17:35:06.218 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system started
17:35:06.219 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:35:06.220 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:35:06.221 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:35:06.222 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:35:06.223 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:35:06.223 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:35:06.224 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for getGroups, name=GetGroupsNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for getGroups, name=GetGroupsAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since last successful login, name=RenewalFailures, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since startup, name=RenewalFailuresTotal, type=java.lang.Long, read-only, descriptor={}]]
17:35:06.225 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:35:06.226 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=UgiMetrics
17:35:06.227 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source UgiMetrics registered.
17:35:06.227 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source UgiMetrics
17:35:06.231 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Control
17:35:06.232 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:35:06.233 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:35:06.234 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:35:06.235 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:35:06.238 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-1835812986, LocalJobRunnerMetrics
17:35:06.239 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:35:06.240 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:35:06.240 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:35:06.241 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:35:06.241 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:35:06.242 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:35:06.242 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:35:06.243 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:35:06.244 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-1835812986
17:35:06.245 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-1835812986 registered.
17:35:06.246 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-1835812986
17:35:06.247 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:35:06.248 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapred.JobClient$1@2f036e24]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:35:06.258 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$10@a78121d]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.connect(Job.java:1536)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1565)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:35:06.263 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:35:06.264 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:35:06.265 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:35:06.267 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:35:06.268 [sbt-bg-threads-1] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
17:35:06.269 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:35:06.270 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:35:06.270 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:35:06.271 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:35:06.272 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics--1153920110, LocalJobRunnerMetrics
17:35:06.273 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:35:06.273 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:35:06.274 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:35:06.275 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:35:06.276 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:35:06.276 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:35:06.277 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:35:06.280 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:35:06.280 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics--1153920110
17:35:06.281 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics--1153920110 registered.
17:35:06.281 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics--1153920110
17:35:06.282 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:35:06.283 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Cluster$1@573c93d0]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:193)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:35:06.286 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:35:06.296 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$11@9409609]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:35:06.300 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:35:06.310 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:35:06.326 [sbt-bg-threads-1] DEBUG o.a.hadoop.mapreduce.JobSubmitter - Configuring job job_local1371254538_0001 with file:/tmp/hadoop/mapred/staging/harsh1371254538/.staging/job_local1371254538_0001 as the submit dir
17:35:06.327 [sbt-bg-threads-1] DEBUG o.a.hadoop.mapreduce.JobSubmitter - adding the following namenodes' delegation tokens:[local]
17:35:06.381 [sbt-bg-threads-1] WARN  o.a.h.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
17:35:06.382 [sbt-bg-threads-1] DEBUG o.a.h.mapreduce.JobResourceUploader - default FileSystem: file:///
17:35:06.402 [sbt-bg-threads-1] DEBUG o.apache.hadoop.io.nativeio.NativeIO - Initialized cache for IDs to User/Group mapping with a  cache timeout of 14400 seconds.
17:35:06.404 [sbt-bg-threads-1] INFO  o.a.hadoop.mapreduce.JobSubmitter - Cleaning up the staging area file:/tmp/hadoop/mapred/staging/harsh1371254538/.staging/job_local1371254538_0001
17:35:06.405 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.io.nativeio.NativeIOException: No such file or directory
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.chmod(NativeIO.java:388)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:974)
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:591)
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:572)
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:594)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:752)
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:660)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:35:06.408 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.io.nativeio.NativeIOException: No such file or directory
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.chmod(NativeIO.java:388)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:974)
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:591)
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:572)
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:594)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:752)
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:660)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:35:06.756 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (harsh (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 6cfa8f72
17:35:06.757 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 623d7c9d
17:35:06.760 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - Completed shutdown in 0.004 seconds; Timeouts: 0
17:35:06.771 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - ShutdownHookManager completed shutdown.
17:43:36.984 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Input path recieved by MapReduce Task 1:1
17:43:36.987 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Output path recieved by MapReduce Task 1:\input\data.txt
17:43:37.208 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:43:37.209 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:43:37.217 [sbt-bg-threads-1] WARN  org.apache.hadoop.util.Shell - Did not find winutils.exe: {}
java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\Hadoop\hadoop-3.3.4\bin\bin -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.getQualifiedBinInner(Shell.java:607)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3741)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3736)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3520)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288)
	at org.apache.hadoop.mapred.JobConf.getWorkingDirectory(JobConf.java:672)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:470)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:52)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:43:37.224 [sbt-bg-threads-1] DEBUG org.apache.hadoop.util.Shell - Failed to find winutils.exe
java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\Hadoop\hadoop-3.3.4\bin\bin -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.getQualifiedBinInner(Shell.java:607)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3741)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3736)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3520)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288)
	at org.apache.hadoop.mapred.JobConf.getWorkingDirectory(JobConf.java:672)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:470)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:52)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:43:37.300 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"GetGroups"})
17:43:37.351 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"})
17:43:37.353 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"})
17:43:37.354 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since last successful login"})
17:43:37.356 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since startup"})
17:43:37.363 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
17:43:37.389 [sbt-bg-threads-1] DEBUG o.a.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
17:43:37.419 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
17:43:37.423 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
17:43:37.443 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
17:43:37.445 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
17:43:37.446 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
17:43:37.481 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
17:43:37.540 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Hadoop login
17:43:37.541 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - hadoop login commit
17:43:37.544 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using local user: NTUserPrincipal: harsh
17:43:37.546 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using user: "NTUserPrincipal: harsh" with name: harsh
17:43:37.547 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - User entry: "harsh"
17:43:37.548 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - UGI loginUser: harsh (auth:SIMPLE)
17:43:37.551 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Acquiring creator semaphore for file:///
17:43:37.551 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Acquiring creator semaphore for file:///: duration 0:00.001s
17:43:37.555 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Creating FS file:///
17:43:37.556 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
17:43:37.574 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_112cf419/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:43:37.579 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_112cf419/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:43:37.583 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_112cf419/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:43:37.586 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_112cf419/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:43:37.587 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_112cf419/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:43:37.598 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_112cf419/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:43:37.607 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_112cf419/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:43:37.609 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_112cf419/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:43:37.609 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
17:43:37.610 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
17:43:37.624 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
17:43:37.625 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
17:43:37.633 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Creating FS file:///: duration 0:00.078s
17:43:37.656 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:43:37.657 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:43:37.657 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:43:37.663 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:43:37.665 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from system property: null
17:43:37.666 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from environment variable: null
17:43:37.718 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2-jobtracker.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@456e17f4[fileName=hadoop-metrics2-jobtracker.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:43:37.721 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@11096361[fileName=hadoop-metrics2.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:43:37.788 [sbt-bg-threads-1] WARN  o.a.h.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
17:43:37.791 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: period
17:43:37.792 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: periodMillis
17:43:37.799 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.metrics2.impl.MetricsSystemImpl.droppedPubAll with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Dropped updates by all sinks"})
17:43:37.800 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Publish", "Publishing stats"})
17:43:37.802 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Snapshot", "Snapshot stats"})
17:43:37.807 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:43:37.808 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:43:37.808 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:43:37.897 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:43:37.899 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:43:37.900 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:43:37.901 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sources, name=NumActiveSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sources, name=NumAllSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sinks, name=NumActiveSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sinks, name=NumAllSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Dropped updates by all sinks, name=DroppedPubAll, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for publishing stats, name=PublishNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for publishing stats, name=PublishAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for snapshot stats, name=SnapshotNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for snapshot stats, name=SnapshotAvgTime, type=java.lang.Double, read-only, descriptor={}]]
17:43:37.928 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:43:37.930 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Stats
17:43:37.931 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source MetricsSystem,sub=Stats registered.
17:43:37.933 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
17:43:37.934 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system started
17:43:37.935 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:43:37.936 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:43:37.936 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:43:37.938 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:43:37.938 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:43:37.939 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:43:37.940 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for getGroups, name=GetGroupsNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for getGroups, name=GetGroupsAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since last successful login, name=RenewalFailures, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since startup, name=RenewalFailuresTotal, type=java.lang.Long, read-only, descriptor={}]]
17:43:37.941 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:43:37.942 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=UgiMetrics
17:43:37.943 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source UgiMetrics registered.
17:43:37.944 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source UgiMetrics
17:43:37.950 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Control
17:43:37.952 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:43:37.953 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:43:37.954 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:43:37.956 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:43:37.962 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-1625677207, LocalJobRunnerMetrics
17:43:37.963 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:43:37.964 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:43:37.965 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:43:37.966 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:43:37.967 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:43:37.968 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:43:37.968 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:43:37.969 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:43:37.970 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-1625677207
17:43:37.971 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-1625677207 registered.
17:43:37.972 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-1625677207
17:43:37.973 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:43:37.975 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapred.JobClient$1@2a7bc567]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:43:37.989 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$10@4309d7c4]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.connect(Job.java:1536)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1565)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:43:37.992 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:43:37.994 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:43:37.994 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:43:37.996 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:43:37.997 [sbt-bg-threads-1] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
17:43:38.031 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:43:38.033 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:43:38.034 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:43:38.036 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:43:38.037 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics--1511093478, LocalJobRunnerMetrics
17:43:38.039 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:43:38.040 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:43:38.041 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:43:38.042 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:43:38.043 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:43:38.044 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:43:38.044 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:43:38.045 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:43:38.046 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics--1511093478
17:43:38.047 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics--1511093478 registered.
17:43:38.048 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics--1511093478
17:43:38.048 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:43:38.052 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Cluster$1@3af637b9]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:193)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:43:38.088 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:43:38.098 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$11@6b91c7c9]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:43:38.103 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:43:38.112 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:43:38.130 [sbt-bg-threads-1] DEBUG o.a.hadoop.mapreduce.JobSubmitter - Configuring job job_local421523081_0001 with file:/tmp/hadoop/mapred/staging/harsh421523081/.staging/job_local421523081_0001 as the submit dir
17:43:38.133 [sbt-bg-threads-1] DEBUG o.a.hadoop.mapreduce.JobSubmitter - adding the following namenodes' delegation tokens:[local]
17:43:38.189 [sbt-bg-threads-1] WARN  o.a.h.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
17:43:38.190 [sbt-bg-threads-1] DEBUG o.a.h.mapreduce.JobResourceUploader - default FileSystem: file:///
17:43:38.210 [sbt-bg-threads-1] DEBUG o.apache.hadoop.io.nativeio.NativeIO - Initialized cache for IDs to User/Group mapping with a  cache timeout of 14400 seconds.
17:43:38.212 [sbt-bg-threads-1] INFO  o.a.hadoop.mapreduce.JobSubmitter - Cleaning up the staging area file:/tmp/hadoop/mapred/staging/harsh421523081/.staging/job_local421523081_0001
17:43:38.213 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.io.nativeio.NativeIOException: No such file or directory
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.chmod(NativeIO.java:388)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:974)
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:591)
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:572)
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:594)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:752)
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:660)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:43:38.217 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.io.nativeio.NativeIOException: No such file or directory
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.chmod(NativeIO.java:388)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:974)
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:591)
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:572)
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:594)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:752)
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:660)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:43:38.492 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (harsh (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 5d9ff081
17:43:38.493 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 53580542
17:43:38.496 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - Completed shutdown in 0.004 seconds; Timeouts: 0
17:43:38.508 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - ShutdownHookManager completed shutdown.
17:46:40.698 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Input path recieved by MapReduce Task 1:1
17:46:40.702 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Output path recieved by MapReduce Task 1:\input\data.txt
17:46:40.955 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:46:40.956 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:46:40.964 [sbt-bg-threads-1] WARN  org.apache.hadoop.util.Shell - Did not find winutils.exe: {}
java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\Hadoop\hadoop-3.3.4\bin\bin -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.getQualifiedBinInner(Shell.java:607)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3741)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3736)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3520)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288)
	at org.apache.hadoop.mapred.JobConf.getWorkingDirectory(JobConf.java:672)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:470)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:52)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:46:40.972 [sbt-bg-threads-1] DEBUG org.apache.hadoop.util.Shell - Failed to find winutils.exe
java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\Hadoop\hadoop-3.3.4\bin\bin -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.getQualifiedBinInner(Shell.java:607)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3741)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3736)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3520)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288)
	at org.apache.hadoop.mapred.JobConf.getWorkingDirectory(JobConf.java:672)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:470)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:52)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:46:41.135 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"GetGroups"})
17:46:41.140 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"})
17:46:41.142 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"})
17:46:41.144 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since last successful login"})
17:46:41.145 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since startup"})
17:46:41.157 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
17:46:41.196 [sbt-bg-threads-1] DEBUG o.a.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
17:46:41.238 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
17:46:41.242 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
17:46:41.264 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
17:46:41.265 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
17:46:41.266 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
17:46:41.312 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
17:46:41.372 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Hadoop login
17:46:41.374 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - hadoop login commit
17:46:41.377 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using local user: NTUserPrincipal: harsh
17:46:41.378 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using user: "NTUserPrincipal: harsh" with name: harsh
17:46:41.379 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - User entry: "harsh"
17:46:41.380 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - UGI loginUser: harsh (auth:SIMPLE)
17:46:41.383 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Acquiring creator semaphore for file:///
17:46:41.384 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Acquiring creator semaphore for file:///: duration 0:00.001s
17:46:41.389 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Creating FS file:///
17:46:41.390 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
17:46:41.412 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_597d4864/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:46:41.422 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_597d4864/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:46:41.426 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_597d4864/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:46:41.429 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_597d4864/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:46:41.431 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_597d4864/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:46:41.446 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_597d4864/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:46:41.462 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_597d4864/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:46:41.465 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_597d4864/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:46:41.466 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
17:46:41.467 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
17:46:41.483 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
17:46:41.485 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
17:46:41.496 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Creating FS file:///: duration 0:00.107s
17:46:41.524 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:46:41.525 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:46:41.525 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:46:41.534 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:46:41.536 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from system property: null
17:46:41.537 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from environment variable: null
17:46:41.615 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2-jobtracker.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@82e2925[fileName=hadoop-metrics2-jobtracker.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:46:41.620 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@5e50d10e[fileName=hadoop-metrics2.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:46:41.649 [sbt-bg-threads-1] WARN  o.a.h.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
17:46:41.651 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: period
17:46:41.652 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: periodMillis
17:46:41.662 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.metrics2.impl.MetricsSystemImpl.droppedPubAll with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Dropped updates by all sinks"})
17:46:41.663 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Publish", "Publishing stats"})
17:46:41.664 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Snapshot", "Snapshot stats"})
17:46:41.671 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:46:41.672 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:46:41.673 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:46:41.794 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:46:41.796 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:46:41.797 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:46:41.798 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sources, name=NumActiveSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sources, name=NumAllSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sinks, name=NumActiveSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sinks, name=NumAllSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Dropped updates by all sinks, name=DroppedPubAll, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for publishing stats, name=PublishNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for publishing stats, name=PublishAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for snapshot stats, name=SnapshotNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for snapshot stats, name=SnapshotAvgTime, type=java.lang.Double, read-only, descriptor={}]]
17:46:41.832 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:46:41.833 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Stats
17:46:41.834 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source MetricsSystem,sub=Stats registered.
17:46:41.837 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
17:46:41.838 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system started
17:46:41.839 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:46:41.839 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:46:41.840 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:46:41.842 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:46:41.842 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:46:41.843 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:46:41.844 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for getGroups, name=GetGroupsNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for getGroups, name=GetGroupsAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since last successful login, name=RenewalFailures, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since startup, name=RenewalFailuresTotal, type=java.lang.Long, read-only, descriptor={}]]
17:46:41.846 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:46:41.847 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=UgiMetrics
17:46:41.848 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source UgiMetrics registered.
17:46:41.849 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source UgiMetrics
17:46:41.852 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Control
17:46:41.856 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:46:41.857 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:46:41.858 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:46:41.860 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:46:41.866 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-218787165, LocalJobRunnerMetrics
17:46:41.866 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:46:41.867 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:46:41.868 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:46:41.869 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:46:41.870 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:46:41.872 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:46:41.872 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:46:41.872 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:46:41.873 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-218787165
17:46:41.874 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-218787165 registered.
17:46:41.875 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-218787165
17:46:41.877 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:46:41.879 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapred.JobClient$1@66eeb09f]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:46:41.891 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$10@de3f39a]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.connect(Job.java:1536)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1565)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:46:41.894 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:46:41.895 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:46:41.895 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:46:41.898 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:46:41.910 [sbt-bg-threads-1] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
17:46:41.912 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:46:41.912 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:46:41.914 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:46:41.915 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:46:41.915 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-1684408207, LocalJobRunnerMetrics
17:46:41.916 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:46:41.916 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:46:41.917 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:46:41.918 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:46:41.919 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:46:41.919 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:46:41.920 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:46:41.921 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:46:41.922 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-1684408207
17:46:41.923 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-1684408207 registered.
17:46:41.924 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-1684408207
17:46:41.924 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:46:41.979 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Cluster$1@1429655a]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:193)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:46:41.983 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:46:41.993 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$11@323d9696]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:46:41.997 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:46:42.008 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:46:42.032 [sbt-bg-threads-1] DEBUG o.a.hadoop.mapreduce.JobSubmitter - Configuring job job_local1192188501_0001 with file:/tmp/hadoop/mapred/staging/harsh1192188501/.staging/job_local1192188501_0001 as the submit dir
17:46:42.033 [sbt-bg-threads-1] DEBUG o.a.hadoop.mapreduce.JobSubmitter - adding the following namenodes' delegation tokens:[local]
17:46:42.081 [sbt-bg-threads-1] WARN  o.a.h.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
17:46:42.082 [sbt-bg-threads-1] DEBUG o.a.h.mapreduce.JobResourceUploader - default FileSystem: file:///
17:46:42.104 [sbt-bg-threads-1] DEBUG o.apache.hadoop.io.nativeio.NativeIO - Initialized cache for IDs to User/Group mapping with a  cache timeout of 14400 seconds.
17:46:42.106 [sbt-bg-threads-1] INFO  o.a.hadoop.mapreduce.JobSubmitter - Cleaning up the staging area file:/tmp/hadoop/mapred/staging/harsh1192188501/.staging/job_local1192188501_0001
17:46:42.107 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.io.nativeio.NativeIOException: No such file or directory
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.chmod(NativeIO.java:388)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:974)
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:591)
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:572)
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:594)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:752)
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:660)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:46:42.110 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.io.nativeio.NativeIOException: No such file or directory
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.chmod(NativeIO.java:388)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:974)
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:591)
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:572)
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:594)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:752)
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:660)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:46:42.461 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (harsh (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 16235764
17:46:42.463 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 18e4bbd0
17:46:42.466 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - Completed shutdown in 0.006 seconds; Timeouts: 0
17:46:42.477 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - ShutdownHookManager completed shutdown.
17:48:13.991 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Input path recieved by MapReduce Task 1:1
17:48:13.994 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Output path recieved by MapReduce Task 1:\input\data.txt
17:48:14.210 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:48:14.210 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:48:14.218 [sbt-bg-threads-1] WARN  org.apache.hadoop.util.Shell - Did not find winutils.exe: {}
java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\Hadoop\hadoop-3.3.4\bin\bin -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.getQualifiedBinInner(Shell.java:607)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3741)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3736)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3520)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288)
	at org.apache.hadoop.mapred.JobConf.getWorkingDirectory(JobConf.java:672)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:470)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:52)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:48:14.224 [sbt-bg-threads-1] DEBUG org.apache.hadoop.util.Shell - Failed to find winutils.exe
java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\Hadoop\hadoop-3.3.4\bin\bin -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.getQualifiedBinInner(Shell.java:607)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3741)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:3736)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3520)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288)
	at org.apache.hadoop.mapred.JobConf.getWorkingDirectory(JobConf.java:672)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:470)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:52)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:48:14.280 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"GetGroups"})
17:48:14.282 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"})
17:48:14.284 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"})
17:48:14.285 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since last successful login"})
17:48:14.287 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since startup"})
17:48:14.297 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
17:48:14.322 [sbt-bg-threads-1] DEBUG o.a.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
17:48:14.343 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
17:48:14.346 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
17:48:14.359 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
17:48:14.361 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
17:48:14.362 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
17:48:14.386 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
17:48:14.431 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Hadoop login
17:48:14.432 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - hadoop login commit
17:48:14.434 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using local user: NTUserPrincipal: harsh
17:48:14.435 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using user: "NTUserPrincipal: harsh" with name: harsh
17:48:14.436 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - User entry: "harsh"
17:48:14.436 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - UGI loginUser: harsh (auth:SIMPLE)
17:48:14.438 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Acquiring creator semaphore for file:///
17:48:14.439 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Acquiring creator semaphore for file:///: duration 0:00.001s
17:48:14.441 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Creating FS file:///
17:48:14.442 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
17:48:14.460 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_b888d005/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:48:14.468 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_b888d005/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:48:14.471 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_b888d005/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:48:14.473 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_b888d005/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:48:14.475 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_b888d005/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:48:14.488 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_b888d005/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:48:14.500 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_b888d005/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:48:14.502 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_b888d005/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:48:14.502 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
17:48:14.503 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
17:48:14.515 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
17:48:14.515 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
17:48:14.521 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Creating FS file:///: duration 0:00.080s
17:48:14.546 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:48:14.547 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:48:14.547 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:48:14.553 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:48:14.555 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from system property: null
17:48:14.555 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from environment variable: null
17:48:14.609 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2-jobtracker.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@354f9cb7[fileName=hadoop-metrics2-jobtracker.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:48:14.613 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@e81ccc6[fileName=hadoop-metrics2.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:48:14.621 [sbt-bg-threads-1] WARN  o.a.h.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
17:48:14.623 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: period
17:48:14.624 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: periodMillis
17:48:14.630 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.metrics2.impl.MetricsSystemImpl.droppedPubAll with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Dropped updates by all sinks"})
17:48:14.631 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Publish", "Publishing stats"})
17:48:14.632 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Snapshot", "Snapshot stats"})
17:48:14.639 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:48:14.640 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:48:14.640 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:48:14.721 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:48:14.722 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:48:14.722 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:48:14.723 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sources, name=NumActiveSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sources, name=NumAllSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sinks, name=NumActiveSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sinks, name=NumAllSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Dropped updates by all sinks, name=DroppedPubAll, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for publishing stats, name=PublishNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for publishing stats, name=PublishAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for snapshot stats, name=SnapshotNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for snapshot stats, name=SnapshotAvgTime, type=java.lang.Double, read-only, descriptor={}]]
17:48:14.741 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:48:14.742 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Stats
17:48:14.742 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source MetricsSystem,sub=Stats registered.
17:48:14.744 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
17:48:14.745 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system started
17:48:14.747 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:48:14.747 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:48:14.748 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:48:14.749 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:48:14.750 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:48:14.750 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:48:14.751 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for getGroups, name=GetGroupsNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for getGroups, name=GetGroupsAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since last successful login, name=RenewalFailures, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since startup, name=RenewalFailuresTotal, type=java.lang.Long, read-only, descriptor={}]]
17:48:14.752 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:48:14.753 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=UgiMetrics
17:48:14.753 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source UgiMetrics registered.
17:48:14.754 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source UgiMetrics
17:48:14.756 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Control
17:48:14.758 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:48:14.759 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:48:14.760 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:48:14.776 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:48:14.780 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-2064014516, LocalJobRunnerMetrics
17:48:14.781 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:48:14.782 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:48:14.782 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:48:14.783 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:48:14.784 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:48:14.784 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:48:14.785 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:48:14.786 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:48:14.786 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-2064014516
17:48:14.786 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-2064014516 registered.
17:48:14.787 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-2064014516
17:48:14.787 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:48:14.789 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapred.JobClient$1@6aa514b8]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:48:14.818 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$10@42e5d94d]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.connect(Job.java:1536)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1565)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:48:14.840 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:48:14.841 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:48:14.842 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:48:14.845 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:48:14.846 [sbt-bg-threads-1] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
17:48:14.866 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:48:14.867 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:48:14.868 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:48:14.869 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:48:14.870 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics--2045003558, LocalJobRunnerMetrics
17:48:14.872 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:48:14.872 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:48:14.873 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:48:14.874 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:48:14.874 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:48:14.875 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:48:14.875 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:48:14.876 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:48:14.877 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics--2045003558
17:48:14.878 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics--2045003558 registered.
17:48:14.878 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics--2045003558
17:48:14.879 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:48:14.880 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Cluster$1@41a5c802]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:193)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:48:14.884 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:48:14.894 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$11@4f159074]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:48:14.897 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:48:14.906 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:48:14.920 [sbt-bg-threads-1] DEBUG o.a.hadoop.mapreduce.JobSubmitter - Configuring job job_local1677316822_0001 with file:/tmp/hadoop/mapred/staging/harsh1677316822/.staging/job_local1677316822_0001 as the submit dir
17:48:14.921 [sbt-bg-threads-1] DEBUG o.a.hadoop.mapreduce.JobSubmitter - adding the following namenodes' delegation tokens:[local]
17:48:14.964 [sbt-bg-threads-1] WARN  o.a.h.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
17:48:14.965 [sbt-bg-threads-1] DEBUG o.a.h.mapreduce.JobResourceUploader - default FileSystem: file:///
17:48:14.980 [sbt-bg-threads-1] DEBUG o.apache.hadoop.io.nativeio.NativeIO - Initialized cache for IDs to User/Group mapping with a  cache timeout of 14400 seconds.
17:48:14.982 [sbt-bg-threads-1] INFO  o.a.hadoop.mapreduce.JobSubmitter - Cleaning up the staging area file:/tmp/hadoop/mapred/staging/harsh1677316822/.staging/job_local1677316822_0001
17:48:14.983 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.io.nativeio.NativeIOException: No such file or directory
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.chmod(NativeIO.java:388)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:974)
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:591)
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:572)
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:594)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:752)
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:660)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:48:14.985 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.io.nativeio.NativeIOException: No such file or directory
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.chmod(NativeIO.java:388)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:974)
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:591)
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:572)
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:594)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:752)
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:660)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:48:15.251 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (harsh (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 37bf7595
17:48:15.252 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 39789d12
17:48:15.255 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - Completed shutdown in 0.005 seconds; Timeouts: 0
17:48:15.268 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - ShutdownHookManager completed shutdown.
17:50:20.306 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Input path recieved by MapReduce Task 1:1
17:50:20.310 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Output path recieved by MapReduce Task 1:\input\data.txt
17:50:20.589 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:50:20.590 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:50:20.667 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"GetGroups"})
17:50:20.671 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"})
17:50:20.672 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"})
17:50:20.674 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since last successful login"})
17:50:20.675 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since startup"})
17:50:20.684 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
17:50:20.714 [sbt-bg-threads-1] DEBUG o.a.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
17:50:20.748 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
17:50:20.753 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
17:50:20.760 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path: [C:\Program Files\Java\jdk-11.0.16.1\bin, C:\WINDOWS\Sun\Java\bin, C:\WINDOWS\system32, C:\WINDOWS, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files (x86)\Common Files\Oracle\Java\javapath, C:\Windows\system32, C:\Windows, C:\Windows\System32\Wbem, C:\Windows\System32\WindowsPowerShell\v1.0\, C:\Windows\System32\OpenSSH\, C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common, C:\Program Files\Git\cmd, C:\TDM-GCC-64\bin, C:\Program Files (x86)\Calibre2\, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\PuTTY\, C:\Program Files\dotnet\, C:\Program Files\apache-maven-3.8.2\bin, C:\Program Files\Java\jdk-16.0.2\bin, C:\Program Files\MySQL\MySQL Server 8.0\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Program Files\Dart\dart-sdk\bin, C:\Program Files (x86)\MySQL\Connector J 8.0, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR, C:\ProgramData\chocolatey\bin, C:\Program Files\Java\jdk1.8.0_211\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin, C:\Users\harsh\AppData\Local\Programs\Python\Python39\, C:\Program Files\MySQL\MySQL Shell 8.0\bin\, C:\Users\harsh\Documents\flutter\bin, C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Users\harsh\AppData\Local\Microsoft\WindowsApps, C:\Program Files (x86)\Java\jre1.8.0_271\bin, C:\Users\harsh\AppData\Local\GitHubDesktop\bin, C:\PROGRA~1\Java\JDK18~1.0_2\bin, C:\Users\harsh\AppData\Local\Coursier\data\bin, C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin, ., C:\Program Files\Java\jdk-11.0.16.1\bin, ., .]
17:50:20.762 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk-11.0.16.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\TDM-GCC-64\bin;C:\Program Files (x86)\Calibre2\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\PuTTY\;C:\Program Files\dotnet\;C:\Program Files\apache-maven-3.8.2\bin;C:\Program Files\Java\jdk-16.0.2\bin;C:\Program Files\MySQL\MySQL Server 8.0\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Dart\dart-sdk\bin;C:\Program Files (x86)\MySQL\Connector J 8.0;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\ProgramData\chocolatey\bin;C:\Program Files\Java\jdk1.8.0_211\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin;C:\Users\harsh\AppData\Local\Programs\Python\Python39\;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\harsh\Documents\flutter\bin;C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Users\harsh\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\Java\jre1.8.0_271\bin;C:\Users\harsh\AppData\Local\GitHubDesktop\bin;C:\PROGRA~1\Java\JDK18~1.0_2\bin;C:\Users\harsh\AppData\Local\Coursier\data\bin;C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin;;C:\Program Files\Java\jdk-11.0.16.1\bin;;.
17:50:20.765 [sbt-bg-threads-1] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17:50:20.767 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.PerformanceAdvisory - Falling back to shell based
17:50:20.770 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
17:50:20.811 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
17:50:20.891 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Hadoop login
17:50:20.893 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - hadoop login commit
17:50:20.897 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using local user: NTUserPrincipal: harsh
17:50:20.900 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using user: "NTUserPrincipal: harsh" with name: harsh
17:50:20.901 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - User entry: "harsh"
17:50:20.902 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - UGI loginUser: harsh (auth:SIMPLE)
17:50:20.906 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Acquiring creator semaphore for file:///
17:50:20.907 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Acquiring creator semaphore for file:///: duration 0:00.001s
17:50:20.911 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Creating FS file:///
17:50:20.911 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
17:50:20.935 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_76606406/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:50:20.947 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_76606406/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:50:20.952 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_76606406/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:50:20.957 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_76606406/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:50:20.959 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_76606406/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:50:20.975 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_76606406/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:50:20.995 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_76606406/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:50:20.997 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_76606406/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:50:20.998 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
17:50:21.000 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
17:50:21.019 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
17:50:21.020 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
17:50:21.029 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Creating FS file:///: duration 0:00.118s
17:50:21.058 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:50:21.059 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:50:21.062 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:50:21.070 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:50:21.072 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from system property: null
17:50:21.073 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from environment variable: null
17:50:21.164 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2-jobtracker.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@5f37fa58[fileName=hadoop-metrics2-jobtracker.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:50:21.171 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@7b92b3[fileName=hadoop-metrics2.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:50:21.224 [sbt-bg-threads-1] WARN  o.a.h.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
17:50:21.229 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: period
17:50:21.230 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: periodMillis
17:50:21.244 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.metrics2.impl.MetricsSystemImpl.droppedPubAll with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Dropped updates by all sinks"})
17:50:21.245 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Publish", "Publishing stats"})
17:50:21.247 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Snapshot", "Snapshot stats"})
17:50:21.256 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:50:21.257 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:50:21.259 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:50:21.645 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:50:21.646 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:50:21.647 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:50:21.648 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sources, name=NumActiveSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sources, name=NumAllSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sinks, name=NumActiveSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sinks, name=NumAllSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Dropped updates by all sinks, name=DroppedPubAll, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for publishing stats, name=PublishNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for publishing stats, name=PublishAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for snapshot stats, name=SnapshotNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for snapshot stats, name=SnapshotAvgTime, type=java.lang.Double, read-only, descriptor={}]]
17:50:21.674 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:50:21.675 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Stats
17:50:21.676 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source MetricsSystem,sub=Stats registered.
17:50:21.679 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
17:50:21.680 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system started
17:50:21.681 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:50:21.682 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:50:21.683 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:50:21.685 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:50:21.685 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:50:21.686 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:50:21.687 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for getGroups, name=GetGroupsNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for getGroups, name=GetGroupsAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since last successful login, name=RenewalFailures, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since startup, name=RenewalFailuresTotal, type=java.lang.Long, read-only, descriptor={}]]
17:50:21.688 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:50:21.689 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=UgiMetrics
17:50:21.690 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source UgiMetrics registered.
17:50:21.691 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source UgiMetrics
17:50:21.696 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Control
17:50:21.698 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:50:21.699 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:50:21.700 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:50:21.701 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:50:21.705 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-319238221, LocalJobRunnerMetrics
17:50:21.706 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:50:21.707 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:50:21.708 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:50:21.710 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:50:21.711 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:50:21.711 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:50:21.712 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:50:21.713 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:50:21.713 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-319238221
17:50:21.714 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-319238221 registered.
17:50:21.714 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-319238221
17:50:21.714 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:50:21.723 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapred.JobClient$1@780e9a1b]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:50:21.734 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$10@5a9d2367]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.connect(Job.java:1536)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1565)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:50:21.739 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:50:21.740 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:50:21.741 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:50:21.743 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:50:21.744 [sbt-bg-threads-1] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
17:50:21.745 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:50:21.746 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:50:21.747 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:50:21.747 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:50:21.748 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-642139083, LocalJobRunnerMetrics
17:50:21.749 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:50:21.750 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:50:21.750 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:50:21.751 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:50:21.751 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:50:21.752 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:50:21.752 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:50:21.753 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:50:21.754 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-642139083
17:50:21.756 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-642139083 registered.
17:50:21.756 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-642139083
17:50:21.757 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:50:21.758 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Cluster$1@5236459b]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:193)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:50:21.762 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:50:21.772 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$11@5774a5ed]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:50:21.776 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:50:21.783 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:50:21.796 [sbt-bg-threads-1] DEBUG o.a.hadoop.mapreduce.JobSubmitter - Configuring job job_local2103445082_0001 with file:/tmp/hadoop/mapred/staging/harsh2103445082/.staging/job_local2103445082_0001 as the submit dir
17:50:21.797 [sbt-bg-threads-1] DEBUG o.a.hadoop.mapreduce.JobSubmitter - adding the following namenodes' delegation tokens:[local]
17:50:21.864 [sbt-bg-threads-1] WARN  o.a.h.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
17:50:21.865 [sbt-bg-threads-1] DEBUG o.a.h.mapreduce.JobResourceUploader - default FileSystem: file:///
17:50:21.942 [sbt-bg-threads-1] INFO  o.a.hadoop.mapreduce.JobSubmitter - Cleaning up the staging area file:/tmp/hadoop/mapred/staging/harsh2103445082/.staging/job_local2103445082_0001
17:50:21.943 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.util.Shell$ExitCodeException: ChangeFileModeByMask error (3): The system cannot find the path specified.



	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1007)
	at org.apache.hadoop.util.Shell.run(Shell.java:900)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1212)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1306)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1288)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:591)
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:572)
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:594)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:752)
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:660)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:50:21.947 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.util.Shell$ExitCodeException: ChangeFileModeByMask error (3): The system cannot find the path specified.



	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1007)
	at org.apache.hadoop.util.Shell.run(Shell.java:900)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1212)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1306)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1288)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:591)
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:572)
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:594)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:752)
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:660)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:50:22.272 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (harsh (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: f510afd
17:50:22.273 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 196f567
17:50:22.276 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - Completed shutdown in 0.004 seconds; Timeouts: 0
17:50:22.288 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - ShutdownHookManager completed shutdown.
17:55:09.258 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Input path recieved by MapReduce Task 1:1
17:55:09.261 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Output path recieved by MapReduce Task 1:C:\Users\harsh\Downloads\Fall_2022\CS_441\HW1\Homework1\src\main\resources\input\data.txt
17:55:09.494 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:55:09.494 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:55:09.572 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"GetGroups"})
17:55:09.574 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"})
17:55:09.576 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"})
17:55:09.577 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since last successful login"})
17:55:09.578 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since startup"})
17:55:09.587 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
17:55:09.612 [sbt-bg-threads-1] DEBUG o.a.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
17:55:09.633 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
17:55:09.636 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
17:55:09.644 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path: [C:\Program Files\Java\jdk-11.0.16.1\bin, C:\WINDOWS\Sun\Java\bin, C:\WINDOWS\system32, C:\WINDOWS, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files (x86)\Common Files\Oracle\Java\javapath, C:\Windows\system32, C:\Windows, C:\Windows\System32\Wbem, C:\Windows\System32\WindowsPowerShell\v1.0\, C:\Windows\System32\OpenSSH\, C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common, C:\Program Files\Git\cmd, C:\TDM-GCC-64\bin, C:\Program Files (x86)\Calibre2\, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\PuTTY\, C:\Program Files\dotnet\, C:\Program Files\apache-maven-3.8.2\bin, C:\Program Files\Java\jdk-16.0.2\bin, C:\Program Files\MySQL\MySQL Server 8.0\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Program Files\Dart\dart-sdk\bin, C:\Program Files (x86)\MySQL\Connector J 8.0, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR, C:\ProgramData\chocolatey\bin, C:\Program Files\Java\jdk1.8.0_211\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin, C:\Users\harsh\AppData\Local\Programs\Python\Python39\, C:\Program Files\MySQL\MySQL Shell 8.0\bin\, C:\Users\harsh\Documents\flutter\bin, C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Users\harsh\AppData\Local\Microsoft\WindowsApps, C:\Program Files (x86)\Java\jre1.8.0_271\bin, C:\Users\harsh\AppData\Local\GitHubDesktop\bin, C:\PROGRA~1\Java\JDK18~1.0_2\bin, C:\Users\harsh\AppData\Local\Coursier\data\bin, C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin, ., C:\Program Files\Java\jdk-11.0.16.1\bin, ., .]
17:55:09.646 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk-11.0.16.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\TDM-GCC-64\bin;C:\Program Files (x86)\Calibre2\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\PuTTY\;C:\Program Files\dotnet\;C:\Program Files\apache-maven-3.8.2\bin;C:\Program Files\Java\jdk-16.0.2\bin;C:\Program Files\MySQL\MySQL Server 8.0\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Dart\dart-sdk\bin;C:\Program Files (x86)\MySQL\Connector J 8.0;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\ProgramData\chocolatey\bin;C:\Program Files\Java\jdk1.8.0_211\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin;C:\Users\harsh\AppData\Local\Programs\Python\Python39\;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\harsh\Documents\flutter\bin;C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Users\harsh\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\Java\jre1.8.0_271\bin;C:\Users\harsh\AppData\Local\GitHubDesktop\bin;C:\PROGRA~1\Java\JDK18~1.0_2\bin;C:\Users\harsh\AppData\Local\Coursier\data\bin;C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin;;C:\Program Files\Java\jdk-11.0.16.1\bin;;.
17:55:09.649 [sbt-bg-threads-1] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17:55:09.650 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.PerformanceAdvisory - Falling back to shell based
17:55:09.652 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
17:55:09.676 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
17:55:09.739 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Hadoop login
17:55:09.741 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - hadoop login commit
17:55:09.744 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using local user: NTUserPrincipal: harsh
17:55:09.746 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using user: "NTUserPrincipal: harsh" with name: harsh
17:55:09.747 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - User entry: "harsh"
17:55:09.749 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - UGI loginUser: harsh (auth:SIMPLE)
17:55:09.752 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Acquiring creator semaphore for file:///
17:55:09.752 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Acquiring creator semaphore for file:///: duration 0:00.001s
17:55:09.755 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Creating FS file:///
17:55:09.755 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
17:55:09.774 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_228f4c7e/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:55:09.783 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_228f4c7e/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:55:09.787 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_228f4c7e/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:55:09.791 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_228f4c7e/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:55:09.792 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_228f4c7e/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:55:09.806 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_228f4c7e/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:55:09.821 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_228f4c7e/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:55:09.823 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_228f4c7e/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:55:09.824 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
17:55:09.825 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
17:55:09.839 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
17:55:09.840 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
17:55:09.847 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Creating FS file:///: duration 0:00.092s
17:55:09.867 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:55:09.868 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:55:09.869 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:55:09.875 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:55:09.878 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from system property: null
17:55:09.879 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from environment variable: null
17:55:09.955 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2-jobtracker.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@e9d76ea[fileName=hadoop-metrics2-jobtracker.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:55:09.964 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@76fa44a6[fileName=hadoop-metrics2.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:55:09.985 [sbt-bg-threads-1] WARN  o.a.h.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
17:55:09.988 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: period
17:55:09.989 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: periodMillis
17:55:09.999 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.metrics2.impl.MetricsSystemImpl.droppedPubAll with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Dropped updates by all sinks"})
17:55:10.000 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Publish", "Publishing stats"})
17:55:10.001 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Snapshot", "Snapshot stats"})
17:55:10.007 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:55:10.007 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:55:10.131 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:55:10.237 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:55:10.238 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:55:10.239 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:55:10.240 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sources, name=NumActiveSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sources, name=NumAllSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sinks, name=NumActiveSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sinks, name=NumAllSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Dropped updates by all sinks, name=DroppedPubAll, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for publishing stats, name=PublishNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for publishing stats, name=PublishAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for snapshot stats, name=SnapshotNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for snapshot stats, name=SnapshotAvgTime, type=java.lang.Double, read-only, descriptor={}]]
17:55:10.268 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:55:10.269 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Stats
17:55:10.270 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source MetricsSystem,sub=Stats registered.
17:55:10.274 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
17:55:10.275 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system started
17:55:10.276 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:55:10.276 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:55:10.277 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:55:10.279 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:55:10.279 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:55:10.280 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:55:10.280 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for getGroups, name=GetGroupsNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for getGroups, name=GetGroupsAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since last successful login, name=RenewalFailures, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since startup, name=RenewalFailuresTotal, type=java.lang.Long, read-only, descriptor={}]]
17:55:10.282 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:55:10.283 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=UgiMetrics
17:55:10.283 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source UgiMetrics registered.
17:55:10.284 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source UgiMetrics
17:55:10.287 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Control
17:55:10.288 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:55:10.290 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:55:10.291 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:55:10.292 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:55:10.295 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics--801357880, LocalJobRunnerMetrics
17:55:10.296 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:55:10.297 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:55:10.298 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:55:10.299 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:55:10.299 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:55:10.300 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:55:10.301 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:55:10.302 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:55:10.302 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics--801357880
17:55:10.303 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics--801357880 registered.
17:55:10.304 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics--801357880
17:55:10.305 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:55:10.307 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapred.JobClient$1@204f3e48]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:55:10.322 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$10@56d89403]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.connect(Job.java:1536)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1565)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:55:10.335 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:55:10.335 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:55:10.336 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:55:10.338 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:55:10.339 [sbt-bg-threads-1] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
17:55:10.340 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:55:10.341 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:55:10.342 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:55:10.343 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:55:10.344 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-599952667, LocalJobRunnerMetrics
17:55:10.345 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:55:10.346 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:55:10.346 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:55:10.348 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:55:10.349 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:55:10.349 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:55:10.350 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:55:10.395 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:55:10.396 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-599952667
17:55:10.397 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-599952667 registered.
17:55:10.398 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-599952667
17:55:10.399 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:55:10.400 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Cluster$1@1cd20a9c]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:193)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:55:10.403 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:55:10.411 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$11@5b2decaa]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:55:10.415 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:55:10.422 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/src/main/resources/input/data.txt already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:279)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:55:10.424 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/src/main/resources/input/data.txt already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:279)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:55:10.684 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (harsh (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 5015b7c9
17:55:10.686 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 5ed243bb
17:55:10.689 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - Completed shutdown in 0.005 seconds; Timeouts: 0
17:55:10.702 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - ShutdownHookManager completed shutdown.
17:57:15.572 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Input path recieved by MapReduce Task 1:1
17:57:15.576 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Output path recieved by MapReduce Task 1:C:\Users\harsh\Downloads\Fall_2022\CS_441\HW1\Homework1\src\main\resources\input\data.txt
17:57:15.815 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:57:15.817 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:57:15.883 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"GetGroups"})
17:57:15.886 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"})
17:57:15.888 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"})
17:57:15.889 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since last successful login"})
17:57:15.890 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since startup"})
17:57:15.898 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
17:57:15.927 [sbt-bg-threads-1] DEBUG o.a.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
17:57:15.946 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
17:57:15.949 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
17:57:15.957 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path: [C:\Program Files\Java\jdk-11.0.16.1\bin, C:\WINDOWS\Sun\Java\bin, C:\WINDOWS\system32, C:\WINDOWS, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files (x86)\Common Files\Oracle\Java\javapath, C:\Windows\system32, C:\Windows, C:\Windows\System32\Wbem, C:\Windows\System32\WindowsPowerShell\v1.0\, C:\Windows\System32\OpenSSH\, C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common, C:\Program Files\Git\cmd, C:\TDM-GCC-64\bin, C:\Program Files (x86)\Calibre2\, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\PuTTY\, C:\Program Files\dotnet\, C:\Program Files\apache-maven-3.8.2\bin, C:\Program Files\Java\jdk-16.0.2\bin, C:\Program Files\MySQL\MySQL Server 8.0\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Program Files\Dart\dart-sdk\bin, C:\Program Files (x86)\MySQL\Connector J 8.0, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR, C:\ProgramData\chocolatey\bin, C:\Program Files\Java\jdk1.8.0_211\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin, C:\Users\harsh\AppData\Local\Programs\Python\Python39\, C:\Program Files\MySQL\MySQL Shell 8.0\bin\, C:\Users\harsh\Documents\flutter\bin, C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Users\harsh\AppData\Local\Microsoft\WindowsApps, C:\Program Files (x86)\Java\jre1.8.0_271\bin, C:\Users\harsh\AppData\Local\GitHubDesktop\bin, C:\PROGRA~1\Java\JDK18~1.0_2\bin, C:\Users\harsh\AppData\Local\Coursier\data\bin, C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin, ., C:\Program Files\Java\jdk-11.0.16.1\bin, ., .]
17:57:15.959 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk-11.0.16.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\TDM-GCC-64\bin;C:\Program Files (x86)\Calibre2\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\PuTTY\;C:\Program Files\dotnet\;C:\Program Files\apache-maven-3.8.2\bin;C:\Program Files\Java\jdk-16.0.2\bin;C:\Program Files\MySQL\MySQL Server 8.0\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Dart\dart-sdk\bin;C:\Program Files (x86)\MySQL\Connector J 8.0;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\ProgramData\chocolatey\bin;C:\Program Files\Java\jdk1.8.0_211\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin;C:\Users\harsh\AppData\Local\Programs\Python\Python39\;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\harsh\Documents\flutter\bin;C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Users\harsh\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\Java\jre1.8.0_271\bin;C:\Users\harsh\AppData\Local\GitHubDesktop\bin;C:\PROGRA~1\Java\JDK18~1.0_2\bin;C:\Users\harsh\AppData\Local\Coursier\data\bin;C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin;;C:\Program Files\Java\jdk-11.0.16.1\bin;;.
17:57:15.961 [sbt-bg-threads-1] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17:57:15.962 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.PerformanceAdvisory - Falling back to shell based
17:57:15.964 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
17:57:15.990 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
17:57:16.063 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Hadoop login
17:57:16.065 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - hadoop login commit
17:57:16.068 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using local user: NTUserPrincipal: harsh
17:57:16.070 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using user: "NTUserPrincipal: harsh" with name: harsh
17:57:16.071 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - User entry: "harsh"
17:57:16.072 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - UGI loginUser: harsh (auth:SIMPLE)
17:57:16.074 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Acquiring creator semaphore for file:///
17:57:16.075 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Acquiring creator semaphore for file:///: duration 0:00.002s
17:57:16.078 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Creating FS file:///
17:57:16.078 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
17:57:16.095 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_a2745294/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:57:16.102 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_a2745294/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:57:16.105 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_a2745294/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:57:16.108 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_a2745294/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:57:16.110 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_a2745294/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
17:57:16.122 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_a2745294/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:57:16.133 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_a2745294/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:57:16.134 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_a2745294/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
17:57:16.135 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
17:57:16.135 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
17:57:16.148 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
17:57:16.149 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
17:57:16.153 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Creating FS file:///: duration 0:00.075s
17:57:16.172 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:57:16.173 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:57:16.174 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:57:16.179 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:57:16.181 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from system property: null
17:57:16.181 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from environment variable: null
17:57:16.248 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2-jobtracker.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@4101c6a7[fileName=hadoop-metrics2-jobtracker.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:57:16.255 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@4709ebca[fileName=hadoop-metrics2.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:57:16.290 [sbt-bg-threads-1] WARN  o.a.h.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
17:57:16.293 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: period
17:57:16.294 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: periodMillis
17:57:16.302 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.metrics2.impl.MetricsSystemImpl.droppedPubAll with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Dropped updates by all sinks"})
17:57:16.304 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Publish", "Publishing stats"})
17:57:16.305 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Snapshot", "Snapshot stats"})
17:57:16.312 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:57:16.313 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:57:16.314 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:57:16.510 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:57:16.511 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:57:16.512 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:57:16.513 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sources, name=NumActiveSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sources, name=NumAllSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sinks, name=NumActiveSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sinks, name=NumAllSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Dropped updates by all sinks, name=DroppedPubAll, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for publishing stats, name=PublishNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for publishing stats, name=PublishAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for snapshot stats, name=SnapshotNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for snapshot stats, name=SnapshotAvgTime, type=java.lang.Double, read-only, descriptor={}]]
17:57:16.539 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:57:16.540 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Stats
17:57:16.541 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source MetricsSystem,sub=Stats registered.
17:57:16.544 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
17:57:16.545 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system started
17:57:16.546 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:57:16.546 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:57:16.547 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:57:16.549 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:57:16.549 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
17:57:16.550 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:57:16.550 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for getGroups, name=GetGroupsNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for getGroups, name=GetGroupsAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since last successful login, name=RenewalFailures, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since startup, name=RenewalFailuresTotal, type=java.lang.Long, read-only, descriptor={}]]
17:57:16.551 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:57:16.552 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=UgiMetrics
17:57:16.553 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source UgiMetrics registered.
17:57:16.553 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source UgiMetrics
17:57:16.556 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Control
17:57:16.557 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:57:16.559 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:57:16.560 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:57:16.561 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:57:16.563 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-1065200969, LocalJobRunnerMetrics
17:57:16.564 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:57:16.565 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:57:16.565 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:57:16.567 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:57:16.567 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:57:16.568 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:57:16.569 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:57:16.570 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:57:16.571 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-1065200969
17:57:16.571 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-1065200969 registered.
17:57:16.572 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-1065200969
17:57:16.573 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:57:16.574 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapred.JobClient$1@93df960]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:57:16.586 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$10@6b54dca0]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.connect(Job.java:1536)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1565)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:57:16.589 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
17:57:16.589 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
17:57:16.590 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
17:57:16.592 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:57:16.593 [sbt-bg-threads-1] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
17:57:16.594 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:57:16.595 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:57:16.596 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:57:16.597 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
17:57:16.597 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics--59414965, LocalJobRunnerMetrics
17:57:16.598 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
17:57:16.598 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
17:57:16.598 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
17:57:16.599 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
17:57:16.599 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
17:57:16.600 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
17:57:16.600 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
17:57:16.611 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
17:57:16.612 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics--59414965
17:57:16.612 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics--59414965 registered.
17:57:16.613 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics--59414965
17:57:16.614 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
17:57:16.615 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Cluster$1@184944fe]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:193)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:57:16.617 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:57:16.627 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$11@4800a9ad]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:57:16.630 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
17:57:16.636 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/src/main/resources/input/data.txt already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:279)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:57:16.638 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/src/main/resources/input/data.txt already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:279)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
17:57:16.865 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (harsh (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 51c090e3
17:57:16.866 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 5f0764ab
17:57:16.869 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - Completed shutdown in 0.005 seconds; Timeouts: 0
17:57:16.881 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - ShutdownHookManager completed shutdown.
18:00:17.279 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Input path recieved by MapReduce Task 1:1
18:00:17.281 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Output path recieved by MapReduce Task 1:C:\Users\harsh\Downloads\Fall_2022\CS_441\HW1\Homework1\src\main\resources\input\data.txt
18:00:17.500 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
18:00:17.500 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
18:00:17.562 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"GetGroups"})
18:00:17.564 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"})
18:00:17.565 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"})
18:00:17.569 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since last successful login"})
18:00:17.570 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since startup"})
18:00:17.579 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
18:00:17.598 [sbt-bg-threads-1] DEBUG o.a.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
18:00:17.619 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
18:00:17.622 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
18:00:17.627 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path: [C:\Program Files\Java\jdk-11.0.16.1\bin, C:\WINDOWS\Sun\Java\bin, C:\WINDOWS\system32, C:\WINDOWS, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files (x86)\Common Files\Oracle\Java\javapath, C:\Windows\system32, C:\Windows, C:\Windows\System32\Wbem, C:\Windows\System32\WindowsPowerShell\v1.0\, C:\Windows\System32\OpenSSH\, C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common, C:\Program Files\Git\cmd, C:\TDM-GCC-64\bin, C:\Program Files (x86)\Calibre2\, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\PuTTY\, C:\Program Files\dotnet\, C:\Program Files\apache-maven-3.8.2\bin, C:\Program Files\Java\jdk-16.0.2\bin, C:\Program Files\MySQL\MySQL Server 8.0\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Program Files\Dart\dart-sdk\bin, C:\Program Files (x86)\MySQL\Connector J 8.0, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR, C:\ProgramData\chocolatey\bin, C:\Program Files\Java\jdk1.8.0_211\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin, C:\Users\harsh\AppData\Local\Programs\Python\Python39\, C:\Program Files\MySQL\MySQL Shell 8.0\bin\, C:\Users\harsh\Documents\flutter\bin, C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Users\harsh\AppData\Local\Microsoft\WindowsApps, C:\Program Files (x86)\Java\jre1.8.0_271\bin, C:\Users\harsh\AppData\Local\GitHubDesktop\bin, C:\PROGRA~1\Java\JDK18~1.0_2\bin, C:\Users\harsh\AppData\Local\Coursier\data\bin, C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin, ., C:\Program Files\Java\jdk-11.0.16.1\bin, ., .]
18:00:17.628 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk-11.0.16.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\TDM-GCC-64\bin;C:\Program Files (x86)\Calibre2\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\PuTTY\;C:\Program Files\dotnet\;C:\Program Files\apache-maven-3.8.2\bin;C:\Program Files\Java\jdk-16.0.2\bin;C:\Program Files\MySQL\MySQL Server 8.0\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Dart\dart-sdk\bin;C:\Program Files (x86)\MySQL\Connector J 8.0;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\ProgramData\chocolatey\bin;C:\Program Files\Java\jdk1.8.0_211\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin;C:\Users\harsh\AppData\Local\Programs\Python\Python39\;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\harsh\Documents\flutter\bin;C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Users\harsh\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\Java\jre1.8.0_271\bin;C:\Users\harsh\AppData\Local\GitHubDesktop\bin;C:\PROGRA~1\Java\JDK18~1.0_2\bin;C:\Users\harsh\AppData\Local\Coursier\data\bin;C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin;;C:\Program Files\Java\jdk-11.0.16.1\bin;;.
18:00:17.631 [sbt-bg-threads-1] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18:00:17.633 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.PerformanceAdvisory - Falling back to shell based
18:00:17.635 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
18:00:17.663 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
18:00:17.720 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Hadoop login
18:00:17.721 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - hadoop login commit
18:00:17.724 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using local user: NTUserPrincipal: harsh
18:00:17.726 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using user: "NTUserPrincipal: harsh" with name: harsh
18:00:17.727 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - User entry: "harsh"
18:00:17.728 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - UGI loginUser: harsh (auth:SIMPLE)
18:00:17.730 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Acquiring creator semaphore for file:///
18:00:17.731 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Acquiring creator semaphore for file:///: duration 0:00.001s
18:00:17.734 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Creating FS file:///
18:00:17.734 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
18:00:17.756 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_6137a30f/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
18:00:17.767 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_6137a30f/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
18:00:17.771 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_6137a30f/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
18:00:17.774 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_6137a30f/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
18:00:17.775 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_6137a30f/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
18:00:17.788 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_6137a30f/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
18:00:17.800 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_6137a30f/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
18:00:17.802 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_6137a30f/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
18:00:17.804 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
18:00:17.805 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
18:00:17.817 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
18:00:17.819 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
18:00:17.824 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Creating FS file:///: duration 0:00.090s
18:00:17.843 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
18:00:17.844 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
18:00:17.844 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
18:00:17.852 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
18:00:17.854 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from system property: null
18:00:17.855 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from environment variable: null
18:00:18.416 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2-jobtracker.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@27d13fb4[fileName=hadoop-metrics2-jobtracker.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
18:00:18.462 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@69f5c090[fileName=hadoop-metrics2.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
18:00:18.479 [sbt-bg-threads-1] WARN  o.a.h.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
18:00:18.483 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: period
18:00:18.484 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: periodMillis
18:00:18.495 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.metrics2.impl.MetricsSystemImpl.droppedPubAll with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Dropped updates by all sinks"})
18:00:18.497 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Publish", "Publishing stats"})
18:00:18.498 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Snapshot", "Snapshot stats"})
18:00:18.509 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
18:00:18.510 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
18:00:18.710 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
18:00:18.880 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
18:00:18.883 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
18:00:18.885 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
18:00:18.887 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sources, name=NumActiveSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sources, name=NumAllSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sinks, name=NumActiveSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sinks, name=NumAllSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Dropped updates by all sinks, name=DroppedPubAll, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for publishing stats, name=PublishNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for publishing stats, name=PublishAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for snapshot stats, name=SnapshotNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for snapshot stats, name=SnapshotAvgTime, type=java.lang.Double, read-only, descriptor={}]]
18:00:18.948 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
18:00:18.950 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Stats
18:00:18.950 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source MetricsSystem,sub=Stats registered.
18:00:18.953 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
18:00:18.958 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system started
18:00:18.960 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
18:00:18.960 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
18:00:18.961 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
18:00:18.963 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
18:00:18.964 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
18:00:18.965 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
18:00:18.966 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for getGroups, name=GetGroupsNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for getGroups, name=GetGroupsAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since last successful login, name=RenewalFailures, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since startup, name=RenewalFailuresTotal, type=java.lang.Long, read-only, descriptor={}]]
18:00:18.967 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
18:00:18.968 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=UgiMetrics
18:00:18.969 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source UgiMetrics registered.
18:00:18.973 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source UgiMetrics
18:00:18.978 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Control
18:00:18.980 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
18:00:18.982 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
18:00:18.983 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
18:00:18.984 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
18:00:18.992 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-1940523378, LocalJobRunnerMetrics
18:00:18.993 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
18:00:18.995 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
18:00:18.996 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
18:00:18.998 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
18:00:18.999 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
18:00:19.000 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
18:00:19.001 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
18:00:19.004 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
18:00:19.006 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-1940523378
18:00:19.007 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-1940523378 registered.
18:00:19.008 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-1940523378
18:00:19.009 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
18:00:19.010 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapred.JobClient$1@51d9f291]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
18:00:19.025 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$10@7dd049fb]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.connect(Job.java:1536)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1565)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
18:00:19.028 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
18:00:19.029 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
18:00:19.030 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
18:00:19.035 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
18:00:19.036 [sbt-bg-threads-1] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
18:00:19.037 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
18:00:19.038 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
18:00:19.039 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
18:00:19.062 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
18:00:19.064 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics--1342301236, LocalJobRunnerMetrics
18:00:19.065 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
18:00:19.066 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
18:00:19.067 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
18:00:19.067 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
18:00:19.068 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
18:00:19.069 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
18:00:19.069 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
18:00:19.070 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
18:00:19.071 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics--1342301236
18:00:19.072 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics--1342301236 registered.
18:00:19.072 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics--1342301236
18:00:19.073 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
18:00:19.074 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Cluster$1@18f7ddd4]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:193)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
18:00:19.127 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
18:00:19.140 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$11@29a4131c]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
18:00:19.144 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
18:00:19.179 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/src/main/resources/input/data.txt already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:279)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
18:00:19.183 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/src/main/resources/input/data.txt already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:279)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
18:00:19.540 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (harsh (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 6451bca7
18:00:19.541 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 6a964e5d
18:00:19.543 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - Completed shutdown in 0.005 seconds; Timeouts: 0
18:00:19.556 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - ShutdownHookManager completed shutdown.
19:30:28.051 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Input path recieved by MapReduce Task 1:1
19:30:28.054 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Output path recieved by MapReduce Task 1:C:\Users\harsh\Downloads\Fall_2022\CS_441\HW1\Homework1\src\main\resources\input\data.txt
19:30:28.306 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:30:28.307 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:30:28.383 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"GetGroups"})
19:30:28.387 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"})
19:30:28.389 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"})
19:30:28.390 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since last successful login"})
19:30:28.392 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since startup"})
19:30:28.400 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
19:30:28.432 [sbt-bg-threads-1] DEBUG o.a.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
19:30:28.460 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
19:30:28.462 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
19:30:28.470 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path: [C:\Program Files\Java\jdk-11.0.16.1\bin, C:\WINDOWS\Sun\Java\bin, C:\WINDOWS\system32, C:\WINDOWS, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files (x86)\Common Files\Oracle\Java\javapath, C:\Windows\system32, C:\Windows, C:\Windows\System32\Wbem, C:\Windows\System32\WindowsPowerShell\v1.0\, C:\Windows\System32\OpenSSH\, C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common, C:\Program Files\Git\cmd, C:\TDM-GCC-64\bin, C:\Program Files (x86)\Calibre2\, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\PuTTY\, C:\Program Files\dotnet\, C:\Program Files\apache-maven-3.8.2\bin, C:\Program Files\Java\jdk-16.0.2\bin, C:\Program Files\MySQL\MySQL Server 8.0\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Program Files\Dart\dart-sdk\bin, C:\Program Files (x86)\MySQL\Connector J 8.0, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR, C:\ProgramData\chocolatey\bin, C:\Program Files\Java\jdk1.8.0_211\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin, C:\Users\harsh\AppData\Local\Programs\Python\Python39\, C:\Program Files\MySQL\MySQL Shell 8.0\bin\, C:\Users\harsh\Documents\flutter\bin, C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Users\harsh\AppData\Local\Microsoft\WindowsApps, C:\Program Files (x86)\Java\jre1.8.0_271\bin, C:\Users\harsh\AppData\Local\GitHubDesktop\bin, C:\PROGRA~1\Java\JDK18~1.0_2\bin, C:\Users\harsh\AppData\Local\Coursier\data\bin, C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin, ., C:\Program Files\Java\jdk-11.0.16.1\bin, ., .]
19:30:28.473 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk-11.0.16.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\TDM-GCC-64\bin;C:\Program Files (x86)\Calibre2\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\PuTTY\;C:\Program Files\dotnet\;C:\Program Files\apache-maven-3.8.2\bin;C:\Program Files\Java\jdk-16.0.2\bin;C:\Program Files\MySQL\MySQL Server 8.0\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Dart\dart-sdk\bin;C:\Program Files (x86)\MySQL\Connector J 8.0;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\ProgramData\chocolatey\bin;C:\Program Files\Java\jdk1.8.0_211\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin;C:\Users\harsh\AppData\Local\Programs\Python\Python39\;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\harsh\Documents\flutter\bin;C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Users\harsh\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\Java\jre1.8.0_271\bin;C:\Users\harsh\AppData\Local\GitHubDesktop\bin;C:\PROGRA~1\Java\JDK18~1.0_2\bin;C:\Users\harsh\AppData\Local\Coursier\data\bin;C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin;;C:\Program Files\Java\jdk-11.0.16.1\bin;;.
19:30:28.482 [sbt-bg-threads-1] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19:30:28.484 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.PerformanceAdvisory - Falling back to shell based
19:30:28.486 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
19:30:28.512 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
19:30:28.568 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Hadoop login
19:30:28.570 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - hadoop login commit
19:30:28.574 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using local user: NTUserPrincipal: harsh
19:30:28.581 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using user: "NTUserPrincipal: harsh" with name: harsh
19:30:28.582 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - User entry: "harsh"
19:30:28.583 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - UGI loginUser: harsh (auth:SIMPLE)
19:30:28.586 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Acquiring creator semaphore for file:///
19:30:28.587 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Acquiring creator semaphore for file:///: duration 0:00.002s
19:30:28.590 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Creating FS file:///
19:30:28.591 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
19:30:28.609 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_f54507ed/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:30:28.617 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_f54507ed/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:30:28.621 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_f54507ed/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:30:28.626 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_f54507ed/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:30:28.627 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_f54507ed/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:30:28.640 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_f54507ed/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
19:30:28.653 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_f54507ed/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
19:30:28.656 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_f54507ed/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
19:30:28.657 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
19:30:28.658 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
19:30:28.673 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
19:30:28.674 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
19:30:28.681 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Creating FS file:///: duration 0:00.091s
19:30:28.706 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
19:30:28.706 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
19:30:28.707 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19:30:28.714 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:30:28.717 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from system property: null
19:30:28.718 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from environment variable: null
19:30:28.776 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2-jobtracker.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@22fb72ce[fileName=hadoop-metrics2-jobtracker.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:30:28.783 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@1b8e0c33[fileName=hadoop-metrics2.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:30:28.809 [sbt-bg-threads-1] WARN  o.a.h.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
19:30:28.811 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: period
19:30:28.812 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: periodMillis
19:30:28.820 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.metrics2.impl.MetricsSystemImpl.droppedPubAll with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Dropped updates by all sinks"})
19:30:28.822 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Publish", "Publishing stats"})
19:30:28.823 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Snapshot", "Snapshot stats"})
19:30:28.829 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:30:28.830 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:30:28.830 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:30:28.969 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:30:28.970 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
19:30:28.971 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:30:28.972 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sources, name=NumActiveSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sources, name=NumAllSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sinks, name=NumActiveSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sinks, name=NumAllSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Dropped updates by all sinks, name=DroppedPubAll, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for publishing stats, name=PublishNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for publishing stats, name=PublishAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for snapshot stats, name=SnapshotNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for snapshot stats, name=SnapshotAvgTime, type=java.lang.Double, read-only, descriptor={}]]
19:30:28.997 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:30:28.998 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Stats
19:30:28.999 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source MetricsSystem,sub=Stats registered.
19:30:29.001 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
19:30:29.001 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system started
19:30:29.002 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:30:29.002 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:30:29.003 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:30:29.004 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:30:29.005 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
19:30:29.005 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:30:29.006 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for getGroups, name=GetGroupsNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for getGroups, name=GetGroupsAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since last successful login, name=RenewalFailures, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since startup, name=RenewalFailuresTotal, type=java.lang.Long, read-only, descriptor={}]]
19:30:29.007 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:30:29.008 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=UgiMetrics
19:30:29.008 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source UgiMetrics registered.
19:30:29.009 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source UgiMetrics
19:30:29.011 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Control
19:30:29.012 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:30:29.013 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:30:29.014 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:30:29.015 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:30:29.018 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-2097188988, LocalJobRunnerMetrics
19:30:29.019 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:30:29.020 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:30:29.020 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:30:29.022 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:30:29.022 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
19:30:29.023 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:30:29.023 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
19:30:29.024 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:30:29.025 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-2097188988
19:30:29.026 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-2097188988 registered.
19:30:29.027 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-2097188988
19:30:29.027 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19:30:29.028 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapred.JobClient$1@77e99aff]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:30:29.040 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$10@bfbef00]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.connect(Job.java:1536)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1565)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:30:29.042 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
19:30:29.042 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
19:30:29.042 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19:30:29.043 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:30:29.044 [sbt-bg-threads-1] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
19:30:29.045 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:30:29.046 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:30:29.046 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:30:29.067 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:30:29.067 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics--1342065131, LocalJobRunnerMetrics
19:30:29.068 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:30:29.069 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:30:29.069 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:30:29.070 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:30:29.070 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
19:30:29.071 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:30:29.072 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
19:30:29.073 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:30:29.074 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics--1342065131
19:30:29.074 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics--1342065131 registered.
19:30:29.075 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics--1342065131
19:30:29.075 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19:30:29.076 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Cluster$1@76eb979f]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:193)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:30:29.100 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:30:29.107 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$11@44226d08]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:30:29.110 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:30:29.119 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/src/main/resources/input/data.txt already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:279)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:30:29.122 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/src/main/resources/input/data.txt already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:279)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:30:29.394 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (harsh (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 2d5c0975
19:30:29.397 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 239bf2ae
19:30:29.400 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - Completed shutdown in 0.006 seconds; Timeouts: 0
19:30:29.414 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - ShutdownHookManager completed shutdown.
19:31:44.178 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Input path recieved by MapReduce Task 1:1
19:31:44.181 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Output path recieved by MapReduce Task 1:C:\Users\harsh\Downloads\Fall_2022\CS_441\HW1\Homework1\src\main\resources\input\data.txt
19:31:44.393 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:31:44.393 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:31:44.455 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"GetGroups"})
19:31:44.458 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"})
19:31:44.459 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"})
19:31:44.460 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since last successful login"})
19:31:44.462 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since startup"})
19:31:44.470 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
19:31:44.492 [sbt-bg-threads-1] DEBUG o.a.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
19:31:44.510 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
19:31:44.513 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
19:31:44.520 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path: [C:\Program Files\Java\jdk-11.0.16.1\bin, C:\WINDOWS\Sun\Java\bin, C:\WINDOWS\system32, C:\WINDOWS, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files (x86)\Common Files\Oracle\Java\javapath, C:\Windows\system32, C:\Windows, C:\Windows\System32\Wbem, C:\Windows\System32\WindowsPowerShell\v1.0\, C:\Windows\System32\OpenSSH\, C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common, C:\Program Files\Git\cmd, C:\TDM-GCC-64\bin, C:\Program Files (x86)\Calibre2\, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\PuTTY\, C:\Program Files\dotnet\, C:\Program Files\apache-maven-3.8.2\bin, C:\Program Files\Java\jdk-16.0.2\bin, C:\Program Files\MySQL\MySQL Server 8.0\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Program Files\Dart\dart-sdk\bin, C:\Program Files (x86)\MySQL\Connector J 8.0, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR, C:\ProgramData\chocolatey\bin, C:\Program Files\Java\jdk1.8.0_211\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin, C:\Users\harsh\AppData\Local\Programs\Python\Python39\, C:\Program Files\MySQL\MySQL Shell 8.0\bin\, C:\Users\harsh\Documents\flutter\bin, C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Users\harsh\AppData\Local\Microsoft\WindowsApps, C:\Program Files (x86)\Java\jre1.8.0_271\bin, C:\Users\harsh\AppData\Local\GitHubDesktop\bin, C:\PROGRA~1\Java\JDK18~1.0_2\bin, C:\Users\harsh\AppData\Local\Coursier\data\bin, C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin, ., C:\Program Files\Java\jdk-11.0.16.1\bin, ., .]
19:31:44.521 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk-11.0.16.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\TDM-GCC-64\bin;C:\Program Files (x86)\Calibre2\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\PuTTY\;C:\Program Files\dotnet\;C:\Program Files\apache-maven-3.8.2\bin;C:\Program Files\Java\jdk-16.0.2\bin;C:\Program Files\MySQL\MySQL Server 8.0\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Dart\dart-sdk\bin;C:\Program Files (x86)\MySQL\Connector J 8.0;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\ProgramData\chocolatey\bin;C:\Program Files\Java\jdk1.8.0_211\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin;C:\Users\harsh\AppData\Local\Programs\Python\Python39\;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\harsh\Documents\flutter\bin;C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Users\harsh\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\Java\jre1.8.0_271\bin;C:\Users\harsh\AppData\Local\GitHubDesktop\bin;C:\PROGRA~1\Java\JDK18~1.0_2\bin;C:\Users\harsh\AppData\Local\Coursier\data\bin;C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin;;C:\Program Files\Java\jdk-11.0.16.1\bin;;.
19:31:44.526 [sbt-bg-threads-1] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19:31:44.528 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.PerformanceAdvisory - Falling back to shell based
19:31:44.531 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
19:31:44.558 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
19:31:44.606 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Hadoop login
19:31:44.608 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - hadoop login commit
19:31:44.610 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using local user: NTUserPrincipal: harsh
19:31:44.612 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using user: "NTUserPrincipal: harsh" with name: harsh
19:31:44.612 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - User entry: "harsh"
19:31:44.613 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - UGI loginUser: harsh (auth:SIMPLE)
19:31:44.616 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Acquiring creator semaphore for file:///
19:31:44.616 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Acquiring creator semaphore for file:///: duration 0:00.001s
19:31:44.619 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Creating FS file:///
19:31:44.619 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
19:31:44.637 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5f7704fa/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:31:44.646 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5f7704fa/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:31:44.649 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5f7704fa/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:31:44.652 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5f7704fa/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:31:44.653 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5f7704fa/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:31:44.664 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5f7704fa/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
19:31:44.676 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5f7704fa/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
19:31:44.678 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5f7704fa/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
19:31:44.679 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
19:31:44.680 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
19:31:44.690 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
19:31:44.691 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
19:31:44.696 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Creating FS file:///: duration 0:00.078s
19:31:44.718 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
19:31:44.718 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
19:31:44.719 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19:31:44.725 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:31:44.727 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from system property: null
19:31:44.727 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from environment variable: null
19:31:44.786 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2-jobtracker.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@67608eeb[fileName=hadoop-metrics2-jobtracker.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:31:44.791 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@437c53b1[fileName=hadoop-metrics2.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:31:44.818 [sbt-bg-threads-1] WARN  o.a.h.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
19:31:44.821 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: period
19:31:44.821 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: periodMillis
19:31:44.829 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.metrics2.impl.MetricsSystemImpl.droppedPubAll with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Dropped updates by all sinks"})
19:31:44.830 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Publish", "Publishing stats"})
19:31:44.831 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Snapshot", "Snapshot stats"})
19:31:44.837 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:31:44.838 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:31:44.838 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:31:44.985 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:31:44.986 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
19:31:44.987 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:31:44.988 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sources, name=NumActiveSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sources, name=NumAllSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sinks, name=NumActiveSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sinks, name=NumAllSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Dropped updates by all sinks, name=DroppedPubAll, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for publishing stats, name=PublishNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for publishing stats, name=PublishAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for snapshot stats, name=SnapshotNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for snapshot stats, name=SnapshotAvgTime, type=java.lang.Double, read-only, descriptor={}]]
19:31:45.012 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:31:45.013 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Stats
19:31:45.014 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source MetricsSystem,sub=Stats registered.
19:31:45.017 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
19:31:45.018 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system started
19:31:45.019 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:31:45.020 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:31:45.021 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:31:45.022 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:31:45.023 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
19:31:45.024 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:31:45.024 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for getGroups, name=GetGroupsNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for getGroups, name=GetGroupsAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since last successful login, name=RenewalFailures, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since startup, name=RenewalFailuresTotal, type=java.lang.Long, read-only, descriptor={}]]
19:31:45.026 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:31:45.026 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=UgiMetrics
19:31:45.027 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source UgiMetrics registered.
19:31:45.027 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source UgiMetrics
19:31:45.030 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Control
19:31:45.032 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:31:45.034 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:31:45.035 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:31:45.037 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:31:45.041 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics--2036644278, LocalJobRunnerMetrics
19:31:45.042 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:31:45.042 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:31:45.043 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:31:45.044 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:31:45.045 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
19:31:45.046 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:31:45.046 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
19:31:45.047 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:31:45.048 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics--2036644278
19:31:45.050 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics--2036644278 registered.
19:31:45.050 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics--2036644278
19:31:45.051 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19:31:45.052 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapred.JobClient$1@2b59fd80]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:31:45.061 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$10@7af5066a]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.connect(Job.java:1536)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1565)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:31:45.066 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
19:31:45.067 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
19:31:45.067 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19:31:45.068 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:31:45.070 [sbt-bg-threads-1] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
19:31:45.071 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:31:45.076 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:31:45.077 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:31:45.078 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:31:45.079 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-2072626277, LocalJobRunnerMetrics
19:31:45.080 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:31:45.081 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:31:45.082 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:31:45.082 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:31:45.083 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
19:31:45.084 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:31:45.084 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
19:31:45.085 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:31:45.086 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-2072626277
19:31:45.086 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-2072626277 registered.
19:31:45.087 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-2072626277
19:31:45.087 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19:31:45.088 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Cluster$1@614f36fb]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:193)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:31:45.113 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:31:45.121 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$11@7b5b958c]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:31:45.125 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:31:45.135 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/src/main/resources/input/data.txt already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:279)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:31:45.137 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/src/main/resources/input/data.txt already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:279)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:31:45.351 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (harsh (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 14730283
19:31:45.352 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 1ab4ee7d
19:31:45.355 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - Completed shutdown in 0.004 seconds; Timeouts: 0
19:31:45.364 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - ShutdownHookManager completed shutdown.
19:32:38.695 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Input path recieved by MapReduce Task 1:1
19:32:38.698 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Output path recieved by MapReduce Task 1:C:\Users\harsh\Downloads\Fall_2022\CS_441\HW1\Homework1\src\main\resources\input\data.txt
19:32:38.933 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:32:38.934 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:32:38.998 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"GetGroups"})
19:32:39.001 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"})
19:32:39.002 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"})
19:32:39.004 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since last successful login"})
19:32:39.005 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since startup"})
19:32:39.012 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
19:32:39.039 [sbt-bg-threads-1] DEBUG o.a.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
19:32:39.063 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
19:32:39.066 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
19:32:39.072 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path: [C:\Program Files\Java\jdk-11.0.16.1\bin, C:\WINDOWS\Sun\Java\bin, C:\WINDOWS\system32, C:\WINDOWS, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files (x86)\Common Files\Oracle\Java\javapath, C:\Windows\system32, C:\Windows, C:\Windows\System32\Wbem, C:\Windows\System32\WindowsPowerShell\v1.0\, C:\Windows\System32\OpenSSH\, C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common, C:\Program Files\Git\cmd, C:\TDM-GCC-64\bin, C:\Program Files (x86)\Calibre2\, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\PuTTY\, C:\Program Files\dotnet\, C:\Program Files\apache-maven-3.8.2\bin, C:\Program Files\Java\jdk-16.0.2\bin, C:\Program Files\MySQL\MySQL Server 8.0\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Program Files\Dart\dart-sdk\bin, C:\Program Files (x86)\MySQL\Connector J 8.0, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR, C:\ProgramData\chocolatey\bin, C:\Program Files\Java\jdk1.8.0_211\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin, C:\Users\harsh\AppData\Local\Programs\Python\Python39\, C:\Program Files\MySQL\MySQL Shell 8.0\bin\, C:\Users\harsh\Documents\flutter\bin, C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Users\harsh\AppData\Local\Microsoft\WindowsApps, C:\Program Files (x86)\Java\jre1.8.0_271\bin, C:\Users\harsh\AppData\Local\GitHubDesktop\bin, C:\PROGRA~1\Java\JDK18~1.0_2\bin, C:\Users\harsh\AppData\Local\Coursier\data\bin, C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin, ., C:\Program Files\Java\jdk-11.0.16.1\bin, ., .]
19:32:39.074 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk-11.0.16.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\TDM-GCC-64\bin;C:\Program Files (x86)\Calibre2\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\PuTTY\;C:\Program Files\dotnet\;C:\Program Files\apache-maven-3.8.2\bin;C:\Program Files\Java\jdk-16.0.2\bin;C:\Program Files\MySQL\MySQL Server 8.0\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Dart\dart-sdk\bin;C:\Program Files (x86)\MySQL\Connector J 8.0;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\ProgramData\chocolatey\bin;C:\Program Files\Java\jdk1.8.0_211\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin;C:\Users\harsh\AppData\Local\Programs\Python\Python39\;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\harsh\Documents\flutter\bin;C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Users\harsh\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\Java\jre1.8.0_271\bin;C:\Users\harsh\AppData\Local\GitHubDesktop\bin;C:\PROGRA~1\Java\JDK18~1.0_2\bin;C:\Users\harsh\AppData\Local\Coursier\data\bin;C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin;;C:\Program Files\Java\jdk-11.0.16.1\bin;;.
19:32:39.076 [sbt-bg-threads-1] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19:32:39.077 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.PerformanceAdvisory - Falling back to shell based
19:32:39.079 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
19:32:39.103 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
19:32:39.145 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Hadoop login
19:32:39.147 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - hadoop login commit
19:32:39.149 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using local user: NTUserPrincipal: harsh
19:32:39.153 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using user: "NTUserPrincipal: harsh" with name: harsh
19:32:39.153 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - User entry: "harsh"
19:32:39.154 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - UGI loginUser: harsh (auth:SIMPLE)
19:32:39.157 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Acquiring creator semaphore for file:///
19:32:39.157 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Acquiring creator semaphore for file:///: duration 0:00.001s
19:32:39.160 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Creating FS file:///
19:32:39.162 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
19:32:39.183 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_c68d8d50/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:32:39.190 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_c68d8d50/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:32:39.194 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_c68d8d50/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:32:39.197 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_c68d8d50/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:32:39.199 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_c68d8d50/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:32:39.211 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_c68d8d50/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
19:32:39.225 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_c68d8d50/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
19:32:39.227 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_c68d8d50/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
19:32:39.228 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
19:32:39.228 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
19:32:39.243 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
19:32:39.243 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
19:32:39.250 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Creating FS file:///: duration 0:00.090s
19:32:39.274 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
19:32:39.275 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
19:32:39.276 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19:32:39.282 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:32:39.284 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from system property: null
19:32:39.285 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from environment variable: null
19:32:39.348 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2-jobtracker.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@6ca9fa7e[fileName=hadoop-metrics2-jobtracker.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:32:39.355 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@7ab0af7b[fileName=hadoop-metrics2.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:32:39.358 [sbt-bg-threads-1] WARN  o.a.h.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
19:32:39.361 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: period
19:32:39.362 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: periodMillis
19:32:39.369 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.metrics2.impl.MetricsSystemImpl.droppedPubAll with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Dropped updates by all sinks"})
19:32:39.370 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Publish", "Publishing stats"})
19:32:39.371 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Snapshot", "Snapshot stats"})
19:32:39.377 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:32:39.378 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:32:39.378 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:32:39.461 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:32:39.462 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
19:32:39.462 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:32:39.463 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sources, name=NumActiveSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sources, name=NumAllSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sinks, name=NumActiveSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sinks, name=NumAllSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Dropped updates by all sinks, name=DroppedPubAll, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for publishing stats, name=PublishNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for publishing stats, name=PublishAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for snapshot stats, name=SnapshotNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for snapshot stats, name=SnapshotAvgTime, type=java.lang.Double, read-only, descriptor={}]]
19:32:39.483 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:32:39.484 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Stats
19:32:39.485 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source MetricsSystem,sub=Stats registered.
19:32:39.486 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
19:32:39.487 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system started
19:32:39.488 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:32:39.488 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:32:39.489 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:32:39.490 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:32:39.490 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
19:32:39.490 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:32:39.492 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for getGroups, name=GetGroupsNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for getGroups, name=GetGroupsAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since last successful login, name=RenewalFailures, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since startup, name=RenewalFailuresTotal, type=java.lang.Long, read-only, descriptor={}]]
19:32:39.493 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:32:39.494 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=UgiMetrics
19:32:39.495 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source UgiMetrics registered.
19:32:39.495 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source UgiMetrics
19:32:39.498 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Control
19:32:39.500 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:32:39.501 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:32:39.502 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:32:39.503 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:32:39.505 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-1185739481, LocalJobRunnerMetrics
19:32:39.506 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:32:39.507 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:32:39.507 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:32:39.509 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:32:39.509 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
19:32:39.510 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:32:39.510 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
19:32:39.511 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:32:39.512 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-1185739481
19:32:39.513 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-1185739481 registered.
19:32:39.513 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-1185739481
19:32:39.514 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19:32:39.515 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapred.JobClient$1@320531c8]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:32:39.526 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$10@32f7c835]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.connect(Job.java:1536)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1565)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:32:39.529 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
19:32:39.529 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
19:32:39.530 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19:32:39.531 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:32:39.532 [sbt-bg-threads-1] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
19:32:39.533 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:32:39.533 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:32:39.534 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:32:39.535 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:32:39.535 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-1568712425, LocalJobRunnerMetrics
19:32:39.536 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:32:39.537 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:32:39.537 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:32:39.538 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:32:39.539 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
19:32:39.539 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:32:39.539 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
19:32:39.540 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:32:39.541 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-1568712425
19:32:39.541 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-1568712425 registered.
19:32:39.542 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-1568712425
19:32:39.542 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19:32:39.543 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Cluster$1@71d9d925]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:193)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:32:39.545 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:32:39.551 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$11@523acf32]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:32:39.554 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:32:39.561 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/src/main/resources/input/data.txt already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:279)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:32:39.564 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/src/main/resources/input/data.txt already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:279)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:32:39.844 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (harsh (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 5c31336c
19:32:39.845 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 52f6c69a
19:32:39.848 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - Completed shutdown in 0.005 seconds; Timeouts: 0
19:32:39.862 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - ShutdownHookManager completed shutdown.
19:40:24.477 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Input path recieved by MapReduce Task 1:1
19:40:24.479 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Output path recieved by MapReduce Task 1:C:\Users\harsh\Downloads\Fall_2022\CS_441\HW1\Homework1\src\main\resources\input\data.txt
19:40:24.699 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:40:24.700 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:40:24.760 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"GetGroups"})
19:40:24.763 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"})
19:40:24.765 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"})
19:40:24.766 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since last successful login"})
19:40:24.767 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since startup"})
19:40:24.775 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
19:40:24.806 [sbt-bg-threads-1] DEBUG o.a.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
19:40:24.831 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
19:40:24.833 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
19:40:24.842 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path: [C:\Program Files\Java\jdk-11.0.16.1\bin, C:\WINDOWS\Sun\Java\bin, C:\WINDOWS\system32, C:\WINDOWS, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files (x86)\Common Files\Oracle\Java\javapath, C:\Windows\system32, C:\Windows, C:\Windows\System32\Wbem, C:\Windows\System32\WindowsPowerShell\v1.0\, C:\Windows\System32\OpenSSH\, C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common, C:\Program Files\Git\cmd, C:\TDM-GCC-64\bin, C:\Program Files (x86)\Calibre2\, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\PuTTY\, C:\Program Files\dotnet\, C:\Program Files\apache-maven-3.8.2\bin, C:\Program Files\Java\jdk-16.0.2\bin, C:\Program Files\MySQL\MySQL Server 8.0\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Program Files\Dart\dart-sdk\bin, C:\Program Files (x86)\MySQL\Connector J 8.0, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR, C:\ProgramData\chocolatey\bin, C:\Program Files\Java\jdk1.8.0_211\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin, C:\Users\harsh\AppData\Local\Programs\Python\Python39\, C:\Program Files\MySQL\MySQL Shell 8.0\bin\, C:\Users\harsh\Documents\flutter\bin, C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Users\harsh\AppData\Local\Microsoft\WindowsApps, C:\Program Files (x86)\Java\jre1.8.0_271\bin, C:\Users\harsh\AppData\Local\GitHubDesktop\bin, C:\PROGRA~1\Java\JDK18~1.0_2\bin, C:\Users\harsh\AppData\Local\Coursier\data\bin, C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin, ., C:\Program Files\Java\jdk-11.0.16.1\bin, ., .]
19:40:24.844 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk-11.0.16.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\TDM-GCC-64\bin;C:\Program Files (x86)\Calibre2\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\PuTTY\;C:\Program Files\dotnet\;C:\Program Files\apache-maven-3.8.2\bin;C:\Program Files\Java\jdk-16.0.2\bin;C:\Program Files\MySQL\MySQL Server 8.0\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Dart\dart-sdk\bin;C:\Program Files (x86)\MySQL\Connector J 8.0;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\ProgramData\chocolatey\bin;C:\Program Files\Java\jdk1.8.0_211\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin;C:\Users\harsh\AppData\Local\Programs\Python\Python39\;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\harsh\Documents\flutter\bin;C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Users\harsh\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\Java\jre1.8.0_271\bin;C:\Users\harsh\AppData\Local\GitHubDesktop\bin;C:\PROGRA~1\Java\JDK18~1.0_2\bin;C:\Users\harsh\AppData\Local\Coursier\data\bin;C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin;;C:\Program Files\Java\jdk-11.0.16.1\bin;;.
19:40:24.847 [sbt-bg-threads-1] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19:40:24.849 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.PerformanceAdvisory - Falling back to shell based
19:40:24.851 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
19:40:24.876 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
19:40:24.922 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Hadoop login
19:40:24.924 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - hadoop login commit
19:40:24.926 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using local user: NTUserPrincipal: harsh
19:40:24.929 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using user: "NTUserPrincipal: harsh" with name: harsh
19:40:24.930 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - User entry: "harsh"
19:40:24.931 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - UGI loginUser: harsh (auth:SIMPLE)
19:40:24.933 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Acquiring creator semaphore for file:///
19:40:24.934 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Acquiring creator semaphore for file:///: duration 0:00.001s
19:40:24.936 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Creating FS file:///
19:40:24.938 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
19:40:24.957 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5bcc4c5c/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:40:24.965 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5bcc4c5c/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:40:24.969 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5bcc4c5c/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:40:24.972 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5bcc4c5c/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:40:24.974 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5bcc4c5c/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:40:24.988 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5bcc4c5c/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
19:40:25.001 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5bcc4c5c/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
19:40:25.004 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_5bcc4c5c/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
19:40:25.005 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
19:40:25.006 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
19:40:25.018 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
19:40:25.019 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
19:40:25.024 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Creating FS file:///: duration 0:00.088s
19:40:25.049 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
19:40:25.050 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
19:40:25.051 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19:40:25.058 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:40:25.061 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from system property: null
19:40:25.062 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from environment variable: null
19:40:25.121 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2-jobtracker.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@789bc996[fileName=hadoop-metrics2-jobtracker.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:40:25.127 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@28b63e[fileName=hadoop-metrics2.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:40:25.147 [sbt-bg-threads-1] WARN  o.a.h.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
19:40:25.151 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: period
19:40:25.151 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: periodMillis
19:40:25.161 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.metrics2.impl.MetricsSystemImpl.droppedPubAll with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Dropped updates by all sinks"})
19:40:25.163 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Publish", "Publishing stats"})
19:40:25.164 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={"Snapshot", "Snapshot stats"})
19:40:25.227 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:40:25.227 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:40:25.228 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:40:25.308 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:40:25.308 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
19:40:25.309 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:40:25.310 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sources, name=NumActiveSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sources, name=NumAllSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sinks, name=NumActiveSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sinks, name=NumAllSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Dropped updates by all sinks, name=DroppedPubAll, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for publishing stats, name=PublishNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for publishing stats, name=PublishAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for snapshot stats, name=SnapshotNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for snapshot stats, name=SnapshotAvgTime, type=java.lang.Double, read-only, descriptor={}]]
19:40:25.333 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:40:25.334 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Stats
19:40:25.335 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source MetricsSystem,sub=Stats registered.
19:40:25.337 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
19:40:25.337 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system started
19:40:25.338 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:40:25.339 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:40:25.339 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:40:25.340 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:40:25.341 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
19:40:25.342 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:40:25.342 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for getGroups, name=GetGroupsNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for getGroups, name=GetGroupsAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since last successful login, name=RenewalFailures, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since startup, name=RenewalFailuresTotal, type=java.lang.Long, read-only, descriptor={}]]
19:40:25.343 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:40:25.344 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=UgiMetrics
19:40:25.345 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source UgiMetrics registered.
19:40:25.345 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source UgiMetrics
19:40:25.348 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Control
19:40:25.349 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:40:25.350 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:40:25.351 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:40:25.352 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:40:25.355 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics--1494883755, LocalJobRunnerMetrics
19:40:25.356 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:40:25.357 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:40:25.358 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:40:25.359 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:40:25.359 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
19:40:25.360 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:40:25.361 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
19:40:25.361 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:40:25.362 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics--1494883755
19:40:25.363 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics--1494883755 registered.
19:40:25.363 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics--1494883755
19:40:25.364 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19:40:25.366 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapred.JobClient$1@7b0bc240]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:40:25.379 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$10@1f4312da]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.connect(Job.java:1536)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1565)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:40:25.382 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
19:40:25.382 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
19:40:25.383 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19:40:25.384 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:40:25.386 [sbt-bg-threads-1] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
19:40:25.387 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:40:25.392 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:40:25.394 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:40:25.395 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName="Ops", valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:40:25.396 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-1739536059, LocalJobRunnerMetrics
19:40:25.397 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:40:25.398 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:40:25.398 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:40:25.399 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:40:25.399 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
19:40:25.400 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:40:25.400 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
19:40:25.401 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:40:25.402 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-1739536059
19:40:25.402 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-1739536059 registered.
19:40:25.403 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-1739536059
19:40:25.404 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19:40:25.405 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Cluster$1@702cd7f6]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:193)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:40:25.425 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:40:25.432 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$11@307eb9e9]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:40:25.436 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:40:25.442 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/src/main/resources/input/data.txt already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:279)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:40:25.444 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/src/main/resources/input/data.txt already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:279)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at MapReduceFuncs.runMapReduce.main(MapReduce1.scala:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:40:25.729 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (harsh (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 302a7700
19:40:25.731 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: 3eed8f75
19:40:25.734 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - Completed shutdown in 0.005 seconds; Timeouts: 0
19:40:25.744 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - ShutdownHookManager completed shutdown.
19:53:26.732 [sbt-bg-threads-1] INFO  Application$ - Application starting. Input 1 - 4 to run corresponding MR task:
19:53:26.735 [sbt-bg-threads-1] INFO  Application$ - C:\Users\harsh\Downloads\Fall_2022\CS_441\HW1\Homework1\src\main\resources\input\data.txt
19:53:26.736 [sbt-bg-threads-1] INFO  Application$ - C:\Users\harsh\Downloads\Fall_2022\CS_441\HW1\Homework1\src\main\resources\output
19:53:26.984 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Input path recieved by MapReduce Task 1:C:\Users\harsh\Downloads\Fall_2022\CS_441\HW1\Homework1\src\main\resources\input\data.txt
19:53:26.985 [sbt-bg-threads-1] INFO  MapReduceFuncs.MapReduce1$ - Output path recieved by MapReduce Task 1:C:\Users\harsh\Downloads\Fall_2022\CS_441\HW1\Homework1\src\main\resources\output
19:53:27.223 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:53:27.224 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:53:27.301 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"GetGroups"})
19:53:27.304 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"})
19:53:27.306 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"})
19:53:27.307 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since last successful login"})
19:53:27.309 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since startup"})
19:53:27.316 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
19:53:27.339 [sbt-bg-threads-1] DEBUG o.a.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
19:53:27.358 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
19:53:27.361 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
19:53:27.367 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path: [C:\Program Files\Java\jdk-11.0.16.1\bin, C:\WINDOWS\Sun\Java\bin, C:\WINDOWS\system32, C:\WINDOWS, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files\Java\jdk-11.0.16.1\bin, C:\Program Files (x86)\Common Files\Oracle\Java\javapath, C:\Windows\system32, C:\Windows, C:\Windows\System32\Wbem, C:\Windows\System32\WindowsPowerShell\v1.0\, C:\Windows\System32\OpenSSH\, C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common, C:\Program Files\Git\cmd, C:\TDM-GCC-64\bin, C:\Program Files (x86)\Calibre2\, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\PuTTY\, C:\Program Files\dotnet\, C:\Program Files\apache-maven-3.8.2\bin, C:\Program Files\Java\jdk-16.0.2\bin, C:\Program Files\MySQL\MySQL Server 8.0\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Program Files\Dart\dart-sdk\bin, C:\Program Files (x86)\MySQL\Connector J 8.0, C:\WINDOWS\system32, C:\WINDOWS, C:\WINDOWS\System32\Wbem, C:\WINDOWS\System32\WindowsPowerShell\v1.0\, C:\WINDOWS\System32\OpenSSH\, C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR, C:\ProgramData\chocolatey\bin, C:\Program Files\Java\jdk1.8.0_211\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin, C:\Users\harsh\AppData\Local\Programs\Python\Python39\, C:\Program Files\MySQL\MySQL Shell 8.0\bin\, C:\Users\harsh\Documents\flutter\bin, C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin, C:\Users\harsh\AppData\Roaming\nvm, C:\Program Files\nodejs, C:\Users\harsh\AppData\Local\Microsoft\WindowsApps, C:\Program Files (x86)\Java\jre1.8.0_271\bin, C:\Users\harsh\AppData\Local\GitHubDesktop\bin, C:\PROGRA~1\Java\JDK18~1.0_2\bin, C:\Users\harsh\AppData\Local\Coursier\data\bin, C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin, C:\Hadoop\hadoop-3.3.4\bin, C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin, ., C:\Program Files\Java\jdk-11.0.16.1\bin, ., .]
19:53:27.369 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk-11.0.16.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files\Java\jdk-11.0.16.1\bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\TDM-GCC-64\bin;C:\Program Files (x86)\Calibre2\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\PuTTY\;C:\Program Files\dotnet\;C:\Program Files\apache-maven-3.8.2\bin;C:\Program Files\Java\jdk-16.0.2\bin;C:\Program Files\MySQL\MySQL Server 8.0\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Dart\dart-sdk\bin;C:\Program Files (x86)\MySQL\Connector J 8.0;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\ProgramData\chocolatey\bin;C:\Program Files\Java\jdk1.8.0_211\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin;C:\Users\harsh\AppData\Local\Programs\Python\Python39\;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\harsh\Documents\flutter\bin;C:\Users\harsh\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\harsh\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Users\harsh\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\Java\jre1.8.0_271\bin;C:\Users\harsh\AppData\Local\GitHubDesktop\bin;C:\PROGRA~1\Java\JDK18~1.0_2\bin;C:\Users\harsh\AppData\Local\Coursier\data\bin;C:\Spark\spark-3.3.0-bin-hadoop3\spark-3.3.0-bin-hadoop3\bin;C:\Hadoop\hadoop-3.3.4\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2022.2.1\bin;;C:\Program Files\Java\jdk-11.0.16.1\bin;;.
19:53:27.371 [sbt-bg-threads-1] WARN  o.a.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19:53:27.373 [sbt-bg-threads-1] DEBUG o.a.hadoop.util.PerformanceAdvisory - Falling back to shell based
19:53:27.375 [sbt-bg-threads-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
19:53:27.401 [sbt-bg-threads-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
19:53:27.458 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Hadoop login
19:53:27.460 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - hadoop login commit
19:53:27.463 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using local user: NTUserPrincipal: harsh
19:53:27.466 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - Using user: "NTUserPrincipal: harsh" with name: harsh
19:53:27.467 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - User entry: "harsh"
19:53:27.468 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - UGI loginUser: harsh (auth:SIMPLE)
19:53:27.471 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Acquiring creator semaphore for file:///
19:53:27.472 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Acquiring creator semaphore for file:///: duration 0:00.002s
19:53:27.476 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Starting: Creating FS file:///
19:53:27.476 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
19:53:27.497 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_8ad35a1f/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:53:27.505 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_8ad35a1f/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:53:27.508 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_8ad35a1f/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:53:27.511 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_8ad35a1f/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:53:27.513 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_8ad35a1f/target/bfa9f024/7f4c3a1d/hadoop-common-3.3.4.jar
19:53:27.526 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_8ad35a1f/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
19:53:27.538 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_8ad35a1f/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
19:53:27.540 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /C:/Users/harsh/Downloads/Fall_2022/CS_441/HW1/Homework1/target/bg-jobs/sbt_8ad35a1f/target/b8f7c8d7/a9046592/hadoop-hdfs-client-3.3.4.jar
19:53:27.541 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
19:53:27.542 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
19:53:27.558 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
19:53:27.559 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
19:53:27.566 [sbt-bg-threads-1] DEBUG org.apache.hadoop.fs.FileSystem - Creating FS file:///: duration 0:00.090s
19:53:27.589 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
19:53:27.590 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
19:53:27.590 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19:53:27.596 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:53:27.597 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from system property: null
19:53:27.598 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - from environment variable: null
19:53:27.655 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2-jobtracker.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@6be15728[fileName=hadoop-metrics2-jobtracker.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at Application$.main(Application.scala:18)
	at Application.main(Application.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:53:27.661 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - Could not locate file hadoop-metrics2.properties
org.apache.commons.configuration2.ex.ConfigurationException: Could not locate: org.apache.commons.configuration2.io.FileLocator@49395b7d[fileName=hadoop-metrics2.properties,basePath=<null>,sourceURL=,encoding=<null>,fileSystem=<null>,locationStrategy=<null>]
	at org.apache.commons.configuration2.io.FileLocatorUtils.locateOrThrow(FileLocatorUtils.java:346)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:972)
	at org.apache.commons.configuration2.io.FileHandler.load(FileHandler.java:702)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.loadFirst(MetricsConfig.java:118)
	at org.apache.hadoop.metrics2.impl.MetricsConfig.create(MetricsConfig.java:97)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configure(MetricsSystemImpl.java:482)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:188)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:163)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:62)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:58)
	at org.apache.hadoop.mapred.LocalJobRunnerMetrics.create(LocalJobRunnerMetrics.java:45)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:777)
	at org.apache.hadoop.mapred.LocalJobRunner.<init>(LocalJobRunner.java:770)
	at org.apache.hadoop.mapred.LocalClientProtocolProvider.create(LocalClientProtocolProvider.java:42)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:130)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:109)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:102)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:475)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:454)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:872)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at Application$.main(Application.scala:18)
	at Application.main(Application.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:53:27.672 [sbt-bg-threads-1] WARN  o.a.h.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
19:53:27.674 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: period
19:53:27.675 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: periodMillis
19:53:27.684 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.metrics2.impl.MetricsSystemImpl.droppedPubAll with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Dropped updates by all sinks"})
19:53:27.685 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Publish", "Publishing stats"})
19:53:27.761 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Snapshot", "Snapshot stats"})
19:53:27.767 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:53:27.767 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:53:27.768 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:53:27.875 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:53:27.876 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
19:53:27.877 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:53:27.878 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sources, name=NumActiveSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sources, name=NumAllSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sinks, name=NumActiveSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sinks, name=NumAllSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Dropped updates by all sinks, name=DroppedPubAll, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for publishing stats, name=PublishNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for publishing stats, name=PublishAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for snapshot stats, name=SnapshotNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for snapshot stats, name=SnapshotAvgTime, type=java.lang.Double, read-only, descriptor={}]]
19:53:27.901 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:53:27.901 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Stats
19:53:27.902 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source MetricsSystem,sub=Stats registered.
19:53:27.904 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
19:53:27.905 [sbt-bg-threads-1] INFO  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system started
19:53:27.906 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:53:27.907 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:53:27.907 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:53:27.909 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:53:27.909 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=10
19:53:27.910 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:53:27.911 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for getGroups, name=GetGroupsNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for getGroups, name=GetGroupsAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since last successful login, name=RenewalFailures, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Renewal failures since startup, name=RenewalFailuresTotal, type=java.lang.Long, read-only, descriptor={}]]
19:53:27.913 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:53:27.913 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=UgiMetrics
19:53:27.914 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source UgiMetrics registered.
19:53:27.914 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source UgiMetrics
19:53:27.918 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=MetricsSystem,sub=Control
19:53:27.919 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:53:27.921 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:53:27.922 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:53:27.923 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:53:27.926 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics-1600844844, LocalJobRunnerMetrics
19:53:27.926 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:53:27.927 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:53:27.928 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:53:27.929 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:53:27.930 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
19:53:27.930 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:53:27.931 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
19:53:27.932 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:53:27.933 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics-1600844844
19:53:27.934 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics-1600844844 registered.
19:53:27.934 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics-1600844844
19:53:27.935 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19:53:27.936 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapred.JobClient$1@29d4a54e]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at Application$.main(Application.scala:18)
	at Application.main(Application.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:53:27.948 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$10@5a74a04e]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.connect(Job.java:1536)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1565)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at Application$.main(Application.scala:18)
	at Application.main(Application.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:53:27.950 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.YarnClientProtocolProvider
19:53:27.951 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Cannot pick org.apache.hadoop.mapred.YarnClientProtocolProvider as the ClientProtocolProvider - returned null protocol
19:53:27.952 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Trying ClientProtocolProvider : org.apache.hadoop.mapred.LocalClientProtocolProvider
19:53:27.966 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:53:27.967 [sbt-bg-threads-1] WARN  o.a.h.m.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
19:53:27.968 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:53:27.969 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numMapTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:53:27.970 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksCompleted with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:53:27.971 [sbt-bg-threads-1] DEBUG o.a.h.m.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.LocalJobRunnerMetrics.numReduceTasksLaunched with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={})
19:53:27.972 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - LocalJobRunnerMetrics--1704236069, LocalJobRunnerMetrics
19:53:27.973 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
19:53:27.974 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'MetricsConfig' for key: source.start_mbeans
19:53:27.974 [sbt-bg-threads-1] DEBUG o.a.h.metrics2.impl.MetricsConfig - poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
19:53:27.975 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating attr cache...
19:53:27.975 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done. # tags & metrics=6
19:53:27.976 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Updating info cache...
19:53:27.976 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksCompleted, name=NumMapTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumMapTasksLaunched, name=NumMapTasksLaunched, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksCompleted, name=NumReduceTasksCompleted, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=NumReduceTasksLaunched, name=NumReduceTasksLaunched, type=java.lang.Integer, read-only, descriptor={}]]
19:53:27.977 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - Done
19:53:27.978 [sbt-bg-threads-1] DEBUG o.apache.hadoop.metrics2.util.MBeans - Registered Hadoop:service=JobTracker,name=LocalJobRunnerMetrics--1704236069
19:53:27.986 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSourceAdapter - MBean for source LocalJobRunnerMetrics--1704236069 registered.
19:53:27.986 [sbt-bg-threads-1] DEBUG o.a.h.m.impl.MetricsSystemImpl - Registered source LocalJobRunnerMetrics--1704236069
19:53:27.987 [sbt-bg-threads-1] DEBUG org.apache.hadoop.mapreduce.Cluster - Picked org.apache.hadoop.mapred.LocalClientProtocolProvider as the ClientProtocolProvider
19:53:27.989 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Cluster$1@b64e9c9]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:193)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at Application$.main(Application.scala:18)
	at Application.main(Application.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:53:27.992 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:53:28.001 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedAction [as: harsh (auth:SIMPLE)][action: org.apache.hadoop.mapreduce.Job$11@6b3210d8]
java.lang.Exception: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at Application$.main(Application.scala:18)
	at Application.main(Application.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:53:28.004 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:53:28.012 [sbt-bg-threads-1] WARN  org.apache.hadoop.fs.FileSystem - "local" is a deprecated filesystem name. Use "file:///" instead.
19:53:28.021 [sbt-bg-threads-1] DEBUG o.a.hadoop.mapreduce.JobSubmitter - Configuring job job_local1657281738_0001 with file:/tmp/hadoop/mapred/staging/harsh1657281738/.staging/job_local1657281738_0001 as the submit dir
19:53:28.022 [sbt-bg-threads-1] DEBUG o.a.hadoop.mapreduce.JobSubmitter - adding the following namenodes' delegation tokens:[local]
19:53:28.073 [sbt-bg-threads-1] WARN  o.a.h.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
19:53:28.073 [sbt-bg-threads-1] DEBUG o.a.h.mapreduce.JobResourceUploader - default FileSystem: file:///
19:53:28.121 [sbt-bg-threads-1] INFO  o.a.hadoop.mapreduce.JobSubmitter - Cleaning up the staging area file:/tmp/hadoop/mapred/staging/harsh1657281738/.staging/job_local1657281738_0001
19:53:28.122 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.util.Shell$ExitCodeException: ChangeFileModeByMask error (3): The system cannot find the path specified.



	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1007)
	at org.apache.hadoop.util.Shell.run(Shell.java:900)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1212)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1306)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1288)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:591)
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:572)
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:594)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:752)
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:660)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at Application$.main(Application.scala:18)
	at Application.main(Application.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:53:28.125 [sbt-bg-threads-1] DEBUG o.a.h.security.UserGroupInformation - PrivilegedActionException as: harsh (auth:SIMPLE)
org.apache.hadoop.util.Shell$ExitCodeException: ChangeFileModeByMask error (3): The system cannot find the path specified.



	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1007)
	at org.apache.hadoop.util.Shell.run(Shell.java:900)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1212)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1306)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1288)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:591)
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:572)
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:594)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:752)
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:660)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1571)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1568)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:571)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:571)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:562)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:873)
	at MapReduceFuncs.MapReduce1$.runMapReduce(MapReduce1.scala:54)
	at Application$.main(Application.scala:18)
	at Application.main(Application.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at sbt.Run.invokeMain(Run.scala:143)
	at sbt.Run.execute$1(Run.scala:93)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)
	at sbt.Run$.executeSuccess(Run.scala:186)
	at sbt.Run.runWithLoader(Run.scala:120)
	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)
	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
19:53:28.404 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.FilterFileSystem.close(FilterFileSystem.java:529)); Key: (harsh (auth:SIMPLE))@file://; URI: file:///; Object Identity Hash: 4e25d46
19:53:28.405 [shutdown-hook-0] DEBUG org.apache.hadoop.fs.FileSystem - FileSystem.close() by method: org.apache.hadoop.fs.RawLocalFileSystem.close(RawLocalFileSystem.java:759)); Key: null; URI: file:///; Object Identity Hash: a25a3aa
19:53:28.408 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - Completed shutdown in 0.004 seconds; Timeouts: 0
19:53:28.418 [Thread-3] DEBUG o.a.hadoop.util.ShutdownHookManager - ShutdownHookManager completed shutdown.
